{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comprehensive Comparision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plot\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Area</th>\n",
       "      <th>MajorAxisLength</th>\n",
       "      <th>MinorAxisLength</th>\n",
       "      <th>Eccentricity</th>\n",
       "      <th>ConvexArea</th>\n",
       "      <th>EquivDiameter</th>\n",
       "      <th>Extent</th>\n",
       "      <th>Perimeter</th>\n",
       "      <th>Roundness</th>\n",
       "      <th>AspectRation</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4537</td>\n",
       "      <td>92.229317</td>\n",
       "      <td>64.012769</td>\n",
       "      <td>0.719916</td>\n",
       "      <td>4677</td>\n",
       "      <td>76.004525</td>\n",
       "      <td>0.657536</td>\n",
       "      <td>273.085</td>\n",
       "      <td>0.764510</td>\n",
       "      <td>1.440796</td>\n",
       "      <td>jasmine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2872</td>\n",
       "      <td>74.691881</td>\n",
       "      <td>51.400454</td>\n",
       "      <td>0.725553</td>\n",
       "      <td>3015</td>\n",
       "      <td>60.471018</td>\n",
       "      <td>0.713009</td>\n",
       "      <td>208.317</td>\n",
       "      <td>0.831658</td>\n",
       "      <td>1.453137</td>\n",
       "      <td>jasmine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3048</td>\n",
       "      <td>76.293164</td>\n",
       "      <td>52.043491</td>\n",
       "      <td>0.731211</td>\n",
       "      <td>3132</td>\n",
       "      <td>62.296341</td>\n",
       "      <td>0.759153</td>\n",
       "      <td>210.012</td>\n",
       "      <td>0.868434</td>\n",
       "      <td>1.465950</td>\n",
       "      <td>jasmine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3073</td>\n",
       "      <td>77.033628</td>\n",
       "      <td>51.928487</td>\n",
       "      <td>0.738639</td>\n",
       "      <td>3157</td>\n",
       "      <td>62.551300</td>\n",
       "      <td>0.783529</td>\n",
       "      <td>210.657</td>\n",
       "      <td>0.870203</td>\n",
       "      <td>1.483456</td>\n",
       "      <td>jasmine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3693</td>\n",
       "      <td>85.124785</td>\n",
       "      <td>56.374021</td>\n",
       "      <td>0.749282</td>\n",
       "      <td>3802</td>\n",
       "      <td>68.571668</td>\n",
       "      <td>0.769375</td>\n",
       "      <td>230.332</td>\n",
       "      <td>0.874743</td>\n",
       "      <td>1.510000</td>\n",
       "      <td>jasmine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18180</th>\n",
       "      <td>18181</td>\n",
       "      <td>5853</td>\n",
       "      <td>148.624571</td>\n",
       "      <td>51.029281</td>\n",
       "      <td>0.939210</td>\n",
       "      <td>6008</td>\n",
       "      <td>86.326537</td>\n",
       "      <td>0.498594</td>\n",
       "      <td>332.960</td>\n",
       "      <td>0.663444</td>\n",
       "      <td>2.912535</td>\n",
       "      <td>Gonen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18181</th>\n",
       "      <td>18182</td>\n",
       "      <td>7585</td>\n",
       "      <td>169.593996</td>\n",
       "      <td>58.141659</td>\n",
       "      <td>0.939398</td>\n",
       "      <td>7806</td>\n",
       "      <td>98.272692</td>\n",
       "      <td>0.647461</td>\n",
       "      <td>385.506</td>\n",
       "      <td>0.641362</td>\n",
       "      <td>2.916910</td>\n",
       "      <td>Gonen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18182</th>\n",
       "      <td>18183</td>\n",
       "      <td>6365</td>\n",
       "      <td>154.777085</td>\n",
       "      <td>52.908085</td>\n",
       "      <td>0.939760</td>\n",
       "      <td>6531</td>\n",
       "      <td>90.023162</td>\n",
       "      <td>0.561287</td>\n",
       "      <td>342.253</td>\n",
       "      <td>0.682832</td>\n",
       "      <td>2.925396</td>\n",
       "      <td>Gonen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18183</th>\n",
       "      <td>18184</td>\n",
       "      <td>5960</td>\n",
       "      <td>151.397924</td>\n",
       "      <td>51.474600</td>\n",
       "      <td>0.940427</td>\n",
       "      <td>6189</td>\n",
       "      <td>87.112041</td>\n",
       "      <td>0.492399</td>\n",
       "      <td>343.371</td>\n",
       "      <td>0.635227</td>\n",
       "      <td>2.941216</td>\n",
       "      <td>Gonen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18184</th>\n",
       "      <td>18185</td>\n",
       "      <td>6134</td>\n",
       "      <td>153.081981</td>\n",
       "      <td>51.590606</td>\n",
       "      <td>0.941500</td>\n",
       "      <td>6283</td>\n",
       "      <td>88.374495</td>\n",
       "      <td>0.489975</td>\n",
       "      <td>338.613</td>\n",
       "      <td>0.672274</td>\n",
       "      <td>2.967245</td>\n",
       "      <td>Gonen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18185 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  Area  MajorAxisLength  MinorAxisLength  Eccentricity  \\\n",
       "0          1  4537        92.229317        64.012769      0.719916   \n",
       "1          2  2872        74.691881        51.400454      0.725553   \n",
       "2          3  3048        76.293164        52.043491      0.731211   \n",
       "3          4  3073        77.033628        51.928487      0.738639   \n",
       "4          5  3693        85.124785        56.374021      0.749282   \n",
       "...      ...   ...              ...              ...           ...   \n",
       "18180  18181  5853       148.624571        51.029281      0.939210   \n",
       "18181  18182  7585       169.593996        58.141659      0.939398   \n",
       "18182  18183  6365       154.777085        52.908085      0.939760   \n",
       "18183  18184  5960       151.397924        51.474600      0.940427   \n",
       "18184  18185  6134       153.081981        51.590606      0.941500   \n",
       "\n",
       "       ConvexArea  EquivDiameter    Extent  Perimeter  Roundness  \\\n",
       "0            4677      76.004525  0.657536    273.085   0.764510   \n",
       "1            3015      60.471018  0.713009    208.317   0.831658   \n",
       "2            3132      62.296341  0.759153    210.012   0.868434   \n",
       "3            3157      62.551300  0.783529    210.657   0.870203   \n",
       "4            3802      68.571668  0.769375    230.332   0.874743   \n",
       "...           ...            ...       ...        ...        ...   \n",
       "18180        6008      86.326537  0.498594    332.960   0.663444   \n",
       "18181        7806      98.272692  0.647461    385.506   0.641362   \n",
       "18182        6531      90.023162  0.561287    342.253   0.682832   \n",
       "18183        6189      87.112041  0.492399    343.371   0.635227   \n",
       "18184        6283      88.374495  0.489975    338.613   0.672274   \n",
       "\n",
       "       AspectRation    Class  \n",
       "0          1.440796  jasmine  \n",
       "1          1.453137  jasmine  \n",
       "2          1.465950  jasmine  \n",
       "3          1.483456  jasmine  \n",
       "4          1.510000  jasmine  \n",
       "...             ...      ...  \n",
       "18180      2.912535    Gonen  \n",
       "18181      2.916910    Gonen  \n",
       "18182      2.925396    Gonen  \n",
       "18183      2.941216    Gonen  \n",
       "18184      2.967245    Gonen  \n",
       "\n",
       "[18185 rows x 12 columns]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('dataset_comb.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "jasmine    9985\n",
       "Gonen      8200\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18185, 12)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Area</th>\n",
       "      <th>MajorAxisLength</th>\n",
       "      <th>MinorAxisLength</th>\n",
       "      <th>Eccentricity</th>\n",
       "      <th>ConvexArea</th>\n",
       "      <th>EquivDiameter</th>\n",
       "      <th>Extent</th>\n",
       "      <th>Perimeter</th>\n",
       "      <th>Roundness</th>\n",
       "      <th>AspectRation</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4537</td>\n",
       "      <td>92.229317</td>\n",
       "      <td>64.012769</td>\n",
       "      <td>0.719916</td>\n",
       "      <td>4677</td>\n",
       "      <td>76.004525</td>\n",
       "      <td>0.657536</td>\n",
       "      <td>273.085</td>\n",
       "      <td>0.764510</td>\n",
       "      <td>1.440796</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2872</td>\n",
       "      <td>74.691881</td>\n",
       "      <td>51.400454</td>\n",
       "      <td>0.725553</td>\n",
       "      <td>3015</td>\n",
       "      <td>60.471018</td>\n",
       "      <td>0.713009</td>\n",
       "      <td>208.317</td>\n",
       "      <td>0.831658</td>\n",
       "      <td>1.453137</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3048</td>\n",
       "      <td>76.293164</td>\n",
       "      <td>52.043491</td>\n",
       "      <td>0.731211</td>\n",
       "      <td>3132</td>\n",
       "      <td>62.296341</td>\n",
       "      <td>0.759153</td>\n",
       "      <td>210.012</td>\n",
       "      <td>0.868434</td>\n",
       "      <td>1.465950</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3073</td>\n",
       "      <td>77.033628</td>\n",
       "      <td>51.928487</td>\n",
       "      <td>0.738639</td>\n",
       "      <td>3157</td>\n",
       "      <td>62.551300</td>\n",
       "      <td>0.783529</td>\n",
       "      <td>210.657</td>\n",
       "      <td>0.870203</td>\n",
       "      <td>1.483456</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3693</td>\n",
       "      <td>85.124785</td>\n",
       "      <td>56.374021</td>\n",
       "      <td>0.749282</td>\n",
       "      <td>3802</td>\n",
       "      <td>68.571668</td>\n",
       "      <td>0.769375</td>\n",
       "      <td>230.332</td>\n",
       "      <td>0.874743</td>\n",
       "      <td>1.510000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  Area  MajorAxisLength  MinorAxisLength  Eccentricity  ConvexArea  \\\n",
       "0   1  4537        92.229317        64.012769      0.719916        4677   \n",
       "1   2  2872        74.691881        51.400454      0.725553        3015   \n",
       "2   3  3048        76.293164        52.043491      0.731211        3132   \n",
       "3   4  3073        77.033628        51.928487      0.738639        3157   \n",
       "4   5  3693        85.124785        56.374021      0.749282        3802   \n",
       "\n",
       "   EquivDiameter    Extent  Perimeter  Roundness  AspectRation  Class  \n",
       "0      76.004525  0.657536    273.085   0.764510      1.440796      1  \n",
       "1      60.471018  0.713009    208.317   0.831658      1.453137      1  \n",
       "2      62.296341  0.759153    210.012   0.868434      1.465950      1  \n",
       "3      62.551300  0.783529    210.657   0.870203      1.483456      1  \n",
       "4      68.571668  0.769375    230.332   0.874743      1.510000      1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "df['Class'] = le.fit_transform(df['Class'])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.values[:,:-1]\n",
    "Y = df.values[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fisher Linear Discriminant "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold  1\n",
      "Testing Accuracy =  0.9318706697459584  Training Accuracy =  1.0\n",
      "Fold  2\n",
      "Testing Accuracy =  1.0  Training Accuracy =  0.9999358439725412\n",
      "Fold  3\n",
      "Testing Accuracy =  1.0  Training Accuracy =  0.9999358439725412\n",
      "Fold  4\n",
      "Testing Accuracy =  1.0  Training Accuracy =  0.9998716879450824\n",
      "Fold  5\n",
      "Testing Accuracy =  1.0  Training Accuracy =  0.9998716879450824\n",
      "Fold  6\n",
      "Testing Accuracy =  1.0  Training Accuracy =  0.9999358439725412\n",
      "Fold  7\n",
      "Testing Accuracy =  1.0  Training Accuracy =  0.999871696176546\n",
      "\n",
      "Average test accuracy=  0.9902672385351369 \n",
      "\n",
      "Precision over fold  1  =  1.0\n",
      "Precision over fold  2  =  1.0\n",
      "Precision over fold  3  =  1.0\n",
      "Precision over fold  4  =  1.0\n",
      "Precision over fold  5  =  1.0\n",
      "Precision over fold  6  =  1.0\n",
      "Precision over fold  7  =  1.0\n",
      "\n",
      "\n",
      "Recall over fold  1  =  0.8759635599159075\n",
      "Recall over fold  2  =  1.0\n",
      "Recall over fold  3  =  1.0\n",
      "Recall over fold  4  =  1.0\n",
      "Recall over fold  5  =  1.0\n",
      "Recall over fold  6  =  1.0\n",
      "Recall over fold  7  =  1.0\n"
     ]
    }
   ],
   "source": [
    "#pipe = Pipeline([('scaler', MinMaxScaler()), ('fda', LinearDiscriminantAnalysis())])\n",
    "fda_scores = cross_validate(LinearDiscriminantAnalysis(),X,Y,cv=7,return_train_score=True)\n",
    "for i,(score, scoret) in enumerate(zip(fda_scores['test_score'],fda_scores['train_score'])):\n",
    "    print(\"Fold \",i+1)\n",
    "    print(\"Testing Accuracy = \",score,\" Training Accuracy = \",scoret)\n",
    "    \n",
    "print(\"\\nAverage test accuracy= \",np.average(fda_scores['test_score']),\"\\n\")\n",
    "\n",
    "fda_prec = cross_validate(LinearDiscriminantAnalysis(),X,Y,cv=7,scoring='precision')\n",
    "for i,score in enumerate(fda_prec['test_score']):\n",
    "    print(\"Precision over fold \",i+1,\" = \",score)\n",
    "print(\"\\n\")\n",
    "fda_rec = cross_validate(LinearDiscriminantAnalysis(),X,Y,cv=7,scoring='recall')\n",
    "for i,score in enumerate(fda_rec['test_score']):\n",
    "    print(\"Recall over fold \",i+1,\" = \",score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Perceptron "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold  1\n",
      "Testing Accuracy =  0.941108545034642  Training Accuracy =  1.0\n",
      "Fold  2\n",
      "Testing Accuracy =  1.0  Training Accuracy =  0.9999358439725412\n",
      "Fold  3\n",
      "Testing Accuracy =  1.0  Training Accuracy =  0.9998716879450824\n",
      "Fold  4\n",
      "Testing Accuracy =  1.0  Training Accuracy =  1.0\n",
      "Fold  5\n",
      "Testing Accuracy =  1.0  Training Accuracy =  0.9989093475332007\n",
      "Fold  6\n",
      "Testing Accuracy =  1.0  Training Accuracy =  0.9999358439725412\n",
      "Fold  7\n",
      "Testing Accuracy =  0.9988448209472468  Training Accuracy =  0.9999358480882731\n",
      "\n",
      "Average test accuracy=  0.9914219094259842 \n",
      "\n",
      "Precision over fold  1  =  1.0\n",
      "Precision over fold  2  =  1.0\n",
      "Precision over fold  3  =  1.0\n",
      "Precision over fold  4  =  1.0\n",
      "Precision over fold  5  =  1.0\n",
      "Precision over fold  6  =  1.0\n",
      "Precision over fold  7  =  0.9979006298110566\n",
      "\n",
      "\n",
      "Recall over fold  1  =  0.8927820602662929\n",
      "Recall over fold  2  =  1.0\n",
      "Recall over fold  3  =  1.0\n",
      "Recall over fold  4  =  1.0\n",
      "Recall over fold  5  =  1.0\n",
      "Recall over fold  6  =  1.0\n",
      "Recall over fold  7  =  1.0\n"
     ]
    }
   ],
   "source": [
    "pipeLP = Pipeline([('scaler', StandardScaler()), ('per', Perceptron())])  #or use MinMaxScaler\n",
    "per_scores = cross_validate(pipeLP,X,Y,cv=7,return_train_score=True)\n",
    "for i,(score, scoret) in enumerate(zip(per_scores['test_score'],per_scores['train_score'])):\n",
    "    print(\"Fold \",i+1)\n",
    "    print(\"Testing Accuracy = \",score,\" Training Accuracy = \",scoret)\n",
    "\n",
    "print(\"\\nAverage test accuracy= \",np.average(per_scores['test_score']),\"\\n\")\n",
    "\n",
    "per_prec = cross_validate(pipeLP,X,Y,cv=7,scoring='precision')\n",
    "for i,score in enumerate(per_prec['test_score']):\n",
    "    print(\"Precision over fold \",i+1,\" = \",score)\n",
    "print(\"\\n\")\n",
    "per_rec = cross_validate(pipeLP,X,Y,cv=7,scoring='recall')\n",
    "for i,score in enumerate(per_rec['test_score']):\n",
    "    print(\"Recall over fold \",i+1,\" = \",score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold  1\n",
      "Testing Accuracy =  0.9491916859122402  Training Accuracy =  0.9858215179316097\n",
      "Fold  2\n",
      "Testing Accuracy =  0.9865280985373364  Training Accuracy =  0.9797266953230256\n",
      "Fold  3\n",
      "Testing Accuracy =  0.9911470361816782  Training Accuracy =  0.9776095464168859\n",
      "Fold  4\n",
      "Testing Accuracy =  0.9923017705927637  Training Accuracy =  0.9774170783345095\n",
      "Fold  5\n",
      "Testing Accuracy =  0.9888375673595073  Training Accuracy =  0.9782511066914736\n",
      "Fold  6\n",
      "Testing Accuracy =  0.9888375673595073  Training Accuracy =  0.9797266953230256\n",
      "Fold  7\n",
      "Testing Accuracy =  0.9626492106276473  Training Accuracy =  0.9879394405953298\n",
      "\n",
      "Average test accuracy=  0.9799275623672401 \n",
      "\n",
      "Precision over fold  1  =  0.9153303399615138\n",
      "Precision over fold  2  =  0.9760601915184679\n",
      "Precision over fold  3  =  0.9841379310344828\n",
      "Precision over fold  4  =  0.9861687413554634\n",
      "Precision over fold  5  =  0.9800687285223367\n",
      "Precision over fold  6  =  0.9800687285223367\n",
      "Precision over fold  7  =  0.9363099146421536\n",
      "\n",
      "\n",
      "Recall over fold  1  =  1.0\n",
      "Recall over fold  2  =  1.0\n",
      "Recall over fold  3  =  1.0\n",
      "Recall over fold  4  =  1.0\n",
      "Recall over fold  5  =  1.0\n",
      "Recall over fold  6  =  1.0\n",
      "Recall over fold  7  =  1.0\n"
     ]
    }
   ],
   "source": [
    "#pipe = Pipeline([('scaler', StandardScaler()), ('nb', GaussianNB())]) #scaling not required i think\n",
    "nb_scores = cross_validate(GaussianNB(),X,Y,cv=7,return_train_score=True)\n",
    "for i,(score, scoret) in enumerate(zip(nb_scores['test_score'],nb_scores['train_score'])):\n",
    "    print(\"Fold \",i+1)\n",
    "    print(\"Testing Accuracy = \",score,\" Training Accuracy = \",scoret)\n",
    "\n",
    "print(\"\\nAverage test accuracy= \",np.average(nb_scores['test_score']),\"\\n\")\n",
    "\n",
    "nb_prec = cross_validate(GaussianNB(),X,Y,cv=7,scoring='precision')\n",
    "for i,score in enumerate(nb_prec['test_score']):\n",
    "    print(\"Precision over fold \",i+1,\" = \",score)\n",
    "print(\"\\n\")\n",
    "nb_rec = cross_validate(GaussianNB(),X,Y,cv=7,scoring='recall')\n",
    "for i,score in enumerate(nb_rec['test_score']):\n",
    "    print(\"Recall over fold \",i+1,\" = \",score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold  1\n",
      "Testing Accuracy =  0.9541955350269438  Training Accuracy =  1.0\n",
      "Fold  2\n",
      "Testing Accuracy =  1.0  Training Accuracy =  0.9999358439725412\n",
      "Fold  3\n",
      "Testing Accuracy =  1.0  Training Accuracy =  0.9999358439725412\n",
      "Fold  4\n",
      "Testing Accuracy =  1.0  Training Accuracy =  0.9999358439725412\n",
      "Fold  5\n",
      "Testing Accuracy =  1.0  Training Accuracy =  0.9999358439725412\n",
      "Fold  6\n",
      "Testing Accuracy =  1.0  Training Accuracy =  0.9999358439725412\n",
      "Fold  7\n",
      "Testing Accuracy =  1.0  Training Accuracy =  0.9999358480882731\n",
      "\n",
      "Average test accuracy=  0.9934565050038492 \n",
      "\n",
      "Precision over fold  1  =  1.0\n",
      "Precision over fold  2  =  1.0\n",
      "Precision over fold  3  =  1.0\n",
      "Precision over fold  4  =  1.0\n",
      "Precision over fold  5  =  1.0\n",
      "Precision over fold  6  =  1.0\n",
      "Precision over fold  7  =  1.0\n",
      "\n",
      "\n",
      "Recall over fold  1  =  0.9166082690960056\n",
      "Recall over fold  2  =  1.0\n",
      "Recall over fold  3  =  1.0\n",
      "Recall over fold  4  =  1.0\n",
      "Recall over fold  5  =  1.0\n",
      "Recall over fold  6  =  1.0\n",
      "Recall over fold  7  =  1.0\n"
     ]
    }
   ],
   "source": [
    "pipeLR = Pipeline([('scaler', StandardScaler()), ('lr', LogisticRegression(solver='liblinear'))])\n",
    "lr_scores = cross_validate(pipeLR,X,Y,cv=7,return_train_score=True)\n",
    "for i,(score, scoret) in enumerate(zip(lr_scores['test_score'],lr_scores['train_score'])):\n",
    "    print(\"Fold \",i+1)\n",
    "    print(\"Testing Accuracy = \",score,\" Training Accuracy = \",scoret)\n",
    "\n",
    "print(\"\\nAverage test accuracy= \",np.average(lr_scores['test_score']),\"\\n\")\n",
    "\n",
    "lr_prec = cross_validate(pipeLR,X,Y,cv=7,scoring='precision')\n",
    "for i,score in enumerate(lr_prec['test_score']):\n",
    "    print(\"Precision over fold \",i+1,\" = \",score)\n",
    "print(\"\\n\")\n",
    "lr_rec = cross_validate(pipeLR,X,Y,cv=7,scoring='recall')\n",
    "for i,score in enumerate(lr_rec['test_score']):\n",
    "    print(\"Recall over fold \",i+1,\" = \",score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Artificial Neural Network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold  1\n",
      "Testing Accuracy =  0.9087759815242494  Training Accuracy =  1.0\n",
      "Fold  2\n",
      "Testing Accuracy =  1.0  Training Accuracy =  0.9999358439725412\n",
      "Fold  3\n",
      "Testing Accuracy =  1.0  Training Accuracy =  0.9999358439725412\n",
      "Fold  4\n",
      "Testing Accuracy =  1.0  Training Accuracy =  0.9999358439725412\n",
      "Fold  5\n",
      "Testing Accuracy =  1.0  Training Accuracy =  0.9999358439725412\n",
      "Fold  6\n",
      "Testing Accuracy =  1.0  Training Accuracy =  0.9999358439725412\n",
      "Fold  7\n",
      "Testing Accuracy =  0.9953792837889873  Training Accuracy =  0.9999358480882731\n",
      "\n",
      "Average test accuracy=  0.986307895044748 \n",
      "\n",
      "Precision over fold  1  =  1.0\n",
      "Precision over fold  2  =  1.0\n",
      "Precision over fold  3  =  1.0\n",
      "Precision over fold  4  =  1.0\n",
      "Precision over fold  5  =  1.0\n",
      "Precision over fold  6  =  1.0\n",
      "Precision over fold  7  =  0.9916550764951322\n",
      "\n",
      "\n",
      "Recall over fold  1  =  0.831114225648213\n",
      "Recall over fold  2  =  1.0\n",
      "Recall over fold  3  =  1.0\n",
      "Recall over fold  4  =  1.0\n",
      "Recall over fold  5  =  1.0\n",
      "Recall over fold  6  =  1.0\n",
      "Recall over fold  7  =  1.0\n"
     ]
    }
   ],
   "source": [
    "pipeNN = Pipeline([('scaler', StandardScaler()), ('ann', MLPClassifier())])\n",
    "nn_scores = cross_validate(pipeNN,X,Y,cv=7,return_train_score=True)\n",
    "for i,(score, scoret) in enumerate(zip(nn_scores['test_score'],nn_scores['train_score'])):\n",
    "    print(\"Fold \",i+1)\n",
    "    print(\"Testing Accuracy = \",score,\" Training Accuracy = \",scoret)\n",
    "\n",
    "print(\"\\nAverage test accuracy= \",np.average(nn_scores['test_score']),\"\\n\")\n",
    "\n",
    "nn_prec = cross_validate(pipeNN,X,Y,cv=7,scoring='precision')\n",
    "for i,score in enumerate(nn_prec['test_score']):\n",
    "    print(\"Precision over fold \",i+1,\" = \",score)\n",
    "print(\"\\n\")\n",
    "nn_rec = cross_validate(pipeNN,X,Y,cv=7,scoring='recall')\n",
    "for i,score in enumerate(nn_rec['test_score']):\n",
    "    print(\"Recall over fold \",i+1,\" = \",score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold  1\n",
      "Testing Accuracy =  0.9599692070823711  Training Accuracy =  1.0\n",
      "Fold  2\n",
      "Testing Accuracy =  1.0  Training Accuracy =  0.9999358439725412\n",
      "Fold  3\n",
      "Testing Accuracy =  1.0  Training Accuracy =  0.9999358439725412\n",
      "Fold  4\n",
      "Testing Accuracy =  1.0  Training Accuracy =  0.9999358439725412\n",
      "Fold  5\n",
      "Testing Accuracy =  1.0  Training Accuracy =  0.9999358439725412\n",
      "Fold  6\n",
      "Testing Accuracy =  1.0  Training Accuracy =  0.9999358439725412\n",
      "Fold  7\n",
      "Testing Accuracy =  0.9942241047362341  Training Accuracy =  0.9999358480882731\n",
      "\n",
      "Average test accuracy=  0.9934561874026578 \n",
      "\n",
      "Precision over fold  1  =  0.9596942321056289\n",
      "Precision over fold  2  =  1.0\n",
      "Precision over fold  3  =  1.0\n",
      "Precision over fold  4  =  1.0\n",
      "Precision over fold  5  =  1.0\n",
      "Precision over fold  6  =  1.0\n",
      "Precision over fold  7  =  0.9895905621096461\n",
      "\n",
      "\n",
      "Recall over fold  1  =  0.9677645409950946\n",
      "Recall over fold  2  =  1.0\n",
      "Recall over fold  3  =  1.0\n",
      "Recall over fold  4  =  1.0\n",
      "Recall over fold  5  =  1.0\n",
      "Recall over fold  6  =  1.0\n",
      "Recall over fold  7  =  1.0\n"
     ]
    }
   ],
   "source": [
    "pipesvm = Pipeline([('scaler', StandardScaler()), ('svm', SVC(kernel='rbf'))])  #kernel can linear or rbf or... (linear gives highest accuracy)\n",
    "svm_scores = cross_validate(pipesvm,X,Y,cv=7,return_train_score=True)\n",
    "for i,(score, scoret) in enumerate(zip(svm_scores['test_score'],svm_scores['train_score'])):\n",
    "    print(\"Fold \",i+1)\n",
    "    print(\"Testing Accuracy = \",score,\" Training Accuracy = \",scoret)\n",
    "\n",
    "print(\"\\nAverage test accuracy= \",np.average(svm_scores['test_score']),\"\\n\")\n",
    "\n",
    "svm_prec = cross_validate(pipesvm,X,Y,cv=7,scoring='precision')\n",
    "for i,score in enumerate(svm_prec['test_score']):\n",
    "    print(\"Precision over fold \",i+1,\" = \",score)\n",
    "print(\"\\n\")\n",
    "svm_rec = cross_validate(pipesvm,X,Y,cv=7,scoring='recall')\n",
    "for i,score in enumerate(svm_rec['test_score']):\n",
    "    print(\"Recall over fold \",i+1,\" = \",score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plot.subplots()\n",
    "ax.boxplot([fda_scores['test_score'],per_scores['test_score'],nb_scores['test_score'],lr_scores['test_score'],nn_scores['test_score'],svm_scores['test_score']])\n",
    "ax.set_xticklabels(['Fisher','Perceptron','NB','Log Regr','ANN','SVM'])\n",
    "plot.ylim([0.9,1.01])\n",
    "plot.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Accuracies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plot.subplots()\n",
    "ax.boxplot([fda_scores['train_score'],per_scores['train_score'],nb_scores['train_score'],lr_scores['train_score'],nn_scores['train_score'],svm_scores['train_score']])\n",
    "ax.set_xticklabels(['Fisher','Perceptron','NB','Log Regr','ANN','SVM'])\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
