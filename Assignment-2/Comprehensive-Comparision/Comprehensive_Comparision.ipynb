{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comprehensive Comparision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do a comparative study and analysis of the following Machine Learning models-\n",
    "- Fisher Linear Discriminant\n",
    "- Linear Perceptron\n",
    "- Naive Bayes\n",
    "- Logistic Regression\n",
    "- Artificial Neural Networks and,\n",
    "- Support Vector Machines \n",
    "\n",
    "The models are imported from the sklearn libraries. The data is scaled using the preprocessing sklearn library, StandardScaler and a 7-fold cross validation is done for each model using the sklearn in built method cross_validate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plot\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Area</th>\n",
       "      <th>MajorAxisLength</th>\n",
       "      <th>MinorAxisLength</th>\n",
       "      <th>Eccentricity</th>\n",
       "      <th>ConvexArea</th>\n",
       "      <th>EquivDiameter</th>\n",
       "      <th>Extent</th>\n",
       "      <th>Perimeter</th>\n",
       "      <th>Roundness</th>\n",
       "      <th>AspectRation</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4537</td>\n",
       "      <td>92.229317</td>\n",
       "      <td>64.012769</td>\n",
       "      <td>0.719916</td>\n",
       "      <td>4677</td>\n",
       "      <td>76.004525</td>\n",
       "      <td>0.657536</td>\n",
       "      <td>273.085</td>\n",
       "      <td>0.764510</td>\n",
       "      <td>1.440796</td>\n",
       "      <td>jasmine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2872</td>\n",
       "      <td>74.691881</td>\n",
       "      <td>51.400454</td>\n",
       "      <td>0.725553</td>\n",
       "      <td>3015</td>\n",
       "      <td>60.471018</td>\n",
       "      <td>0.713009</td>\n",
       "      <td>208.317</td>\n",
       "      <td>0.831658</td>\n",
       "      <td>1.453137</td>\n",
       "      <td>jasmine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3048</td>\n",
       "      <td>76.293164</td>\n",
       "      <td>52.043491</td>\n",
       "      <td>0.731211</td>\n",
       "      <td>3132</td>\n",
       "      <td>62.296341</td>\n",
       "      <td>0.759153</td>\n",
       "      <td>210.012</td>\n",
       "      <td>0.868434</td>\n",
       "      <td>1.465950</td>\n",
       "      <td>jasmine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3073</td>\n",
       "      <td>77.033628</td>\n",
       "      <td>51.928487</td>\n",
       "      <td>0.738639</td>\n",
       "      <td>3157</td>\n",
       "      <td>62.551300</td>\n",
       "      <td>0.783529</td>\n",
       "      <td>210.657</td>\n",
       "      <td>0.870203</td>\n",
       "      <td>1.483456</td>\n",
       "      <td>jasmine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3693</td>\n",
       "      <td>85.124785</td>\n",
       "      <td>56.374021</td>\n",
       "      <td>0.749282</td>\n",
       "      <td>3802</td>\n",
       "      <td>68.571668</td>\n",
       "      <td>0.769375</td>\n",
       "      <td>230.332</td>\n",
       "      <td>0.874743</td>\n",
       "      <td>1.510000</td>\n",
       "      <td>jasmine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18180</th>\n",
       "      <td>18181</td>\n",
       "      <td>5853</td>\n",
       "      <td>148.624571</td>\n",
       "      <td>51.029281</td>\n",
       "      <td>0.939210</td>\n",
       "      <td>6008</td>\n",
       "      <td>86.326537</td>\n",
       "      <td>0.498594</td>\n",
       "      <td>332.960</td>\n",
       "      <td>0.663444</td>\n",
       "      <td>2.912535</td>\n",
       "      <td>Gonen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18181</th>\n",
       "      <td>18182</td>\n",
       "      <td>7585</td>\n",
       "      <td>169.593996</td>\n",
       "      <td>58.141659</td>\n",
       "      <td>0.939398</td>\n",
       "      <td>7806</td>\n",
       "      <td>98.272692</td>\n",
       "      <td>0.647461</td>\n",
       "      <td>385.506</td>\n",
       "      <td>0.641362</td>\n",
       "      <td>2.916910</td>\n",
       "      <td>Gonen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18182</th>\n",
       "      <td>18183</td>\n",
       "      <td>6365</td>\n",
       "      <td>154.777085</td>\n",
       "      <td>52.908085</td>\n",
       "      <td>0.939760</td>\n",
       "      <td>6531</td>\n",
       "      <td>90.023162</td>\n",
       "      <td>0.561287</td>\n",
       "      <td>342.253</td>\n",
       "      <td>0.682832</td>\n",
       "      <td>2.925396</td>\n",
       "      <td>Gonen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18183</th>\n",
       "      <td>18184</td>\n",
       "      <td>5960</td>\n",
       "      <td>151.397924</td>\n",
       "      <td>51.474600</td>\n",
       "      <td>0.940427</td>\n",
       "      <td>6189</td>\n",
       "      <td>87.112041</td>\n",
       "      <td>0.492399</td>\n",
       "      <td>343.371</td>\n",
       "      <td>0.635227</td>\n",
       "      <td>2.941216</td>\n",
       "      <td>Gonen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18184</th>\n",
       "      <td>18185</td>\n",
       "      <td>6134</td>\n",
       "      <td>153.081981</td>\n",
       "      <td>51.590606</td>\n",
       "      <td>0.941500</td>\n",
       "      <td>6283</td>\n",
       "      <td>88.374495</td>\n",
       "      <td>0.489975</td>\n",
       "      <td>338.613</td>\n",
       "      <td>0.672274</td>\n",
       "      <td>2.967245</td>\n",
       "      <td>Gonen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18185 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  Area  MajorAxisLength  MinorAxisLength  Eccentricity  \\\n",
       "0          1  4537        92.229317        64.012769      0.719916   \n",
       "1          2  2872        74.691881        51.400454      0.725553   \n",
       "2          3  3048        76.293164        52.043491      0.731211   \n",
       "3          4  3073        77.033628        51.928487      0.738639   \n",
       "4          5  3693        85.124785        56.374021      0.749282   \n",
       "...      ...   ...              ...              ...           ...   \n",
       "18180  18181  5853       148.624571        51.029281      0.939210   \n",
       "18181  18182  7585       169.593996        58.141659      0.939398   \n",
       "18182  18183  6365       154.777085        52.908085      0.939760   \n",
       "18183  18184  5960       151.397924        51.474600      0.940427   \n",
       "18184  18185  6134       153.081981        51.590606      0.941500   \n",
       "\n",
       "       ConvexArea  EquivDiameter    Extent  Perimeter  Roundness  \\\n",
       "0            4677      76.004525  0.657536    273.085   0.764510   \n",
       "1            3015      60.471018  0.713009    208.317   0.831658   \n",
       "2            3132      62.296341  0.759153    210.012   0.868434   \n",
       "3            3157      62.551300  0.783529    210.657   0.870203   \n",
       "4            3802      68.571668  0.769375    230.332   0.874743   \n",
       "...           ...            ...       ...        ...        ...   \n",
       "18180        6008      86.326537  0.498594    332.960   0.663444   \n",
       "18181        7806      98.272692  0.647461    385.506   0.641362   \n",
       "18182        6531      90.023162  0.561287    342.253   0.682832   \n",
       "18183        6189      87.112041  0.492399    343.371   0.635227   \n",
       "18184        6283      88.374495  0.489975    338.613   0.672274   \n",
       "\n",
       "       AspectRation    Class  \n",
       "0          1.440796  jasmine  \n",
       "1          1.453137  jasmine  \n",
       "2          1.465950  jasmine  \n",
       "3          1.483456  jasmine  \n",
       "4          1.510000  jasmine  \n",
       "...             ...      ...  \n",
       "18180      2.912535    Gonen  \n",
       "18181      2.916910    Gonen  \n",
       "18182      2.925396    Gonen  \n",
       "18183      2.941216    Gonen  \n",
       "18184      2.967245    Gonen  \n",
       "\n",
       "[18185 rows x 12 columns]"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('dataset_comb.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "jasmine    9985\n",
       "Gonen      8200\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18185, 12)"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Area</th>\n",
       "      <th>MajorAxisLength</th>\n",
       "      <th>MinorAxisLength</th>\n",
       "      <th>Eccentricity</th>\n",
       "      <th>ConvexArea</th>\n",
       "      <th>EquivDiameter</th>\n",
       "      <th>Extent</th>\n",
       "      <th>Perimeter</th>\n",
       "      <th>Roundness</th>\n",
       "      <th>AspectRation</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4537</td>\n",
       "      <td>92.229317</td>\n",
       "      <td>64.012769</td>\n",
       "      <td>0.719916</td>\n",
       "      <td>4677</td>\n",
       "      <td>76.004525</td>\n",
       "      <td>0.657536</td>\n",
       "      <td>273.085</td>\n",
       "      <td>0.764510</td>\n",
       "      <td>1.440796</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2872</td>\n",
       "      <td>74.691881</td>\n",
       "      <td>51.400454</td>\n",
       "      <td>0.725553</td>\n",
       "      <td>3015</td>\n",
       "      <td>60.471018</td>\n",
       "      <td>0.713009</td>\n",
       "      <td>208.317</td>\n",
       "      <td>0.831658</td>\n",
       "      <td>1.453137</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3048</td>\n",
       "      <td>76.293164</td>\n",
       "      <td>52.043491</td>\n",
       "      <td>0.731211</td>\n",
       "      <td>3132</td>\n",
       "      <td>62.296341</td>\n",
       "      <td>0.759153</td>\n",
       "      <td>210.012</td>\n",
       "      <td>0.868434</td>\n",
       "      <td>1.465950</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3073</td>\n",
       "      <td>77.033628</td>\n",
       "      <td>51.928487</td>\n",
       "      <td>0.738639</td>\n",
       "      <td>3157</td>\n",
       "      <td>62.551300</td>\n",
       "      <td>0.783529</td>\n",
       "      <td>210.657</td>\n",
       "      <td>0.870203</td>\n",
       "      <td>1.483456</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3693</td>\n",
       "      <td>85.124785</td>\n",
       "      <td>56.374021</td>\n",
       "      <td>0.749282</td>\n",
       "      <td>3802</td>\n",
       "      <td>68.571668</td>\n",
       "      <td>0.769375</td>\n",
       "      <td>230.332</td>\n",
       "      <td>0.874743</td>\n",
       "      <td>1.510000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  Area  MajorAxisLength  MinorAxisLength  Eccentricity  ConvexArea  \\\n",
       "0   1  4537        92.229317        64.012769      0.719916        4677   \n",
       "1   2  2872        74.691881        51.400454      0.725553        3015   \n",
       "2   3  3048        76.293164        52.043491      0.731211        3132   \n",
       "3   4  3073        77.033628        51.928487      0.738639        3157   \n",
       "4   5  3693        85.124785        56.374021      0.749282        3802   \n",
       "\n",
       "   EquivDiameter    Extent  Perimeter  Roundness  AspectRation  Class  \n",
       "0      76.004525  0.657536    273.085   0.764510      1.440796      1  \n",
       "1      60.471018  0.713009    208.317   0.831658      1.453137      1  \n",
       "2      62.296341  0.759153    210.012   0.868434      1.465950      1  \n",
       "3      62.551300  0.783529    210.657   0.870203      1.483456      1  \n",
       "4      68.571668  0.769375    230.332   0.874743      1.510000      1  "
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "df['Class'] = le.fit_transform(df['Class'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = shuffle(df)\n",
    "X = df.values[:,1:-1]\n",
    "Y = df.values[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "average= {}\n",
    "maxm= {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fisher Linear Discriminant "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Fisher Linear Discriminant Analysis is a classification technique that identifies the linear combination of features that characterizes or separates two or more classes. \n",
    "The model fits a Gaussian density to each class, assuming that all classes share the same covariance matrix.\n",
    "\n",
    "We import the sklearn LinearDiscrminantAnalysis model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold  1\n",
      "Testing Accuracy =  0.9842186297151655  Training Accuracy =  0.9872329505357028\n",
      "Fold  2\n",
      "Testing Accuracy =  0.9876828329484219  Training Accuracy =  0.9866555462885738\n",
      "Fold  3\n",
      "Testing Accuracy =  0.9907621247113164  Training Accuracy =  0.9861422980689035\n",
      "Fold  4\n",
      "Testing Accuracy =  0.9857582755966128  Training Accuracy =  0.986912170398409\n",
      "Fold  5\n",
      "Testing Accuracy =  0.985373364126251  Training Accuracy =  0.9871046384807852\n",
      "Fold  6\n",
      "Testing Accuracy =  0.9865280985373364  Training Accuracy =  0.986912170398409\n",
      "Fold  7\n",
      "Testing Accuracy =  0.986907970735464  Training Accuracy =  0.9865922504490634\n",
      "\n",
      "Average test accuracy=  0.9867473280529383 \n",
      "\n",
      "Precision over fold  1  =  0.9766001376462491\n",
      "Precision over fold  2  =  0.9793672627235214\n",
      "Precision over fold  3  =  0.986130374479889\n",
      "Precision over fold  4  =  0.9779917469050894\n",
      "Precision over fold  5  =  0.979296066252588\n",
      "Precision over fold  6  =  0.9806629834254144\n",
      "Precision over fold  7  =  0.9793388429752066\n",
      "\n",
      "\n",
      "Recall over fold  1  =  0.9950911640953717\n",
      "Recall over fold  2  =  0.9985974754558204\n",
      "Recall over fold  3  =  0.9971949509116409\n",
      "Recall over fold  4  =  0.9964961457603364\n",
      "Recall over fold  5  =  0.9943938332165382\n",
      "Recall over fold  6  =  0.9950946040644709\n",
      "Recall over fold  7  =  0.9971949509116409\n"
     ]
    }
   ],
   "source": [
    "#pipe = Pipeline([('scaler', MinMaxScaler()), ('fda', LinearDiscriminantAnalysis())]) #scaling not required\n",
    "fda_scores = cross_validate(LinearDiscriminantAnalysis(),X,Y,cv=7,return_train_score=True)\n",
    "for i,(score, scoret) in enumerate(zip(fda_scores['test_score'],fda_scores['train_score'])):\n",
    "    print(\"Fold \",i+1)\n",
    "    print(\"Testing Accuracy = \",score,\" Training Accuracy = \",scoret)\n",
    "\n",
    "average['Fisher Discriminant']= np.average(fda_scores['test_score'])\n",
    "maxm['Fisher Discriminant']=np.amax(fda_scores['test_score'])\n",
    "print(\"\\nAverage test accuracy= \",average['Fisher Discriminant'],\"\\n\")\n",
    "\n",
    "fda_prec = cross_validate(LinearDiscriminantAnalysis(),X,Y,cv=7,scoring='precision')\n",
    "for i,score in enumerate(fda_prec['test_score']):\n",
    "    print(\"Precision over fold \",i+1,\" = \",score)\n",
    "print(\"\\n\")\n",
    "fda_rec = cross_validate(LinearDiscriminantAnalysis(),X,Y,cv=7,scoring='recall')\n",
    "for i,score in enumerate(fda_rec['test_score']):\n",
    "    print(\"Recall over fold \",i+1,\" = \",score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Perceptron "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Perceptron is a linear classification algorithm that makes its predictions based on a linear predictor function combining a set of weights with the feature vector. It uses the Gradient Descent Algorithm to update the weights based on misclassified points on each iteration.\n",
    "\n",
    "We import the sklearn Perceptron model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold  1\n",
      "Testing Accuracy =  0.9846035411855273  Training Accuracy =  0.9851158016295631\n",
      "Fold  2\n",
      "Testing Accuracy =  0.9896073903002309  Training Accuracy =  0.9874254186180792\n",
      "Fold  3\n",
      "Testing Accuracy =  0.9911470361816782  Training Accuracy =  0.9846025534098929\n",
      "Fold  4\n",
      "Testing Accuracy =  0.9803695150115473  Training Accuracy =  0.9820363123115416\n",
      "Fold  5\n",
      "Testing Accuracy =  0.9842186297151655  Training Accuracy =  0.9849874895746455\n",
      "Fold  6\n",
      "Testing Accuracy =  0.9407236335642802  Training Accuracy =  0.9423878873420157\n",
      "Fold  7\n",
      "Testing Accuracy =  0.9811320754716981  Training Accuracy =  0.9849884526558892\n",
      "\n",
      "Average test accuracy=  0.9788288316328754 \n",
      "\n",
      "Precision over fold  1  =  0.9779310344827586\n",
      "Precision over fold  2  =  0.9915671117357695\n",
      "Precision over fold  3  =  0.9902166317260657\n",
      "Precision over fold  4  =  0.9764542936288089\n",
      "Precision over fold  5  =  0.9766162310866575\n",
      "Precision over fold  6  =  0.9930286599535244\n",
      "Precision over fold  7  =  0.9771309771309772\n",
      "\n",
      "\n",
      "Recall over fold  1  =  0.9943899018232819\n",
      "Recall over fold  2  =  0.9894810659186536\n",
      "Recall over fold  3  =  0.9936886395511921\n",
      "Recall over fold  4  =  0.9880868955851436\n",
      "Recall over fold  5  =  0.9950946040644709\n",
      "Recall over fold  6  =  0.8983882270497547\n",
      "Recall over fold  7  =  0.9887798036465638\n"
     ]
    }
   ],
   "source": [
    "pipeLP = Pipeline([('scaler', StandardScaler()), ('per', Perceptron())])  #or use MinMaxScaler\n",
    "per_scores = cross_validate(pipeLP,X,Y,cv=7,return_train_score=True)\n",
    "for i,(score, scoret) in enumerate(zip(per_scores['test_score'],per_scores['train_score'])):\n",
    "    print(\"Fold \",i+1)\n",
    "    print(\"Testing Accuracy = \",score,\" Training Accuracy = \",scoret)\n",
    "\n",
    "average['Perceptron']=np.average(per_scores['test_score'])\n",
    "maxm['Perceptron']=np.amax(per_scores['test_score'])\n",
    "print(\"\\nAverage test accuracy= \",average['Perceptron'],\"\\n\")\n",
    "\n",
    "per_prec = cross_validate(pipeLP,X,Y,cv=7,scoring='precision')\n",
    "for i,score in enumerate(per_prec['test_score']):\n",
    "    print(\"Precision over fold \",i+1,\" = \",score)\n",
    "print(\"\\n\")\n",
    "per_rec = cross_validate(pipeLP,X,Y,cv=7,scoring='recall')\n",
    "for i,score in enumerate(per_rec['test_score']):\n",
    "    print(\"Recall over fold \",i+1,\" = \",score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes algorithms are a set of supervised statistical classification machine learning algorithms based on the Bayes probability theorem.\n",
    "\n",
    "Bayes theorem states that:\n",
    "\n",
    "$$P(A|B) = \\frac{P(B/A) * P(A)}{P(B)}$$$$P(A|B) = \\frac{P(B/A) * P(A)}{P(B/A) * P(A) + P(C/A) * P(A)}$$\n",
    "An important assumption made by Bayes theorem is that the value of a particular feature is independent from the value of any other feature for a given the class.\n",
    "\n",
    "We import the sklearn GaussianNB model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold  1\n",
      "Testing Accuracy =  0.9803695150115473  Training Accuracy =  0.9840893051902226\n",
      "Fold  2\n",
      "Testing Accuracy =  0.9842186297151655  Training Accuracy =  0.9836402129980112\n",
      "Fold  3\n",
      "Testing Accuracy =  0.9896073903002309  Training Accuracy =  0.9827420286135883\n",
      "Fold  4\n",
      "Testing Accuracy =  0.9830638953040801  Training Accuracy =  0.9838968371078463\n",
      "Fold  5\n",
      "Testing Accuracy =  0.9838337182448037  Training Accuracy =  0.9838326810803875\n",
      "Fold  6\n",
      "Testing Accuracy =  0.9838337182448037  Training Accuracy =  0.9836402129980112\n",
      "Fold  7\n",
      "Testing Accuracy =  0.9811320754716981  Training Accuracy =  0.9837695663330768\n",
      "\n",
      "Average test accuracy=  0.9837227060417614 \n",
      "\n",
      "Precision over fold  1  =  0.9692832764505119\n",
      "Precision over fold  2  =  0.9726962457337884\n",
      "Precision over fold  3  =  0.9820813232253618\n",
      "Precision over fold  4  =  0.973305954825462\n",
      "Precision over fold  5  =  0.973990417522245\n",
      "Precision over fold  6  =  0.9733424470266575\n",
      "Precision over fold  7  =  0.9680489462950373\n",
      "\n",
      "\n",
      "Recall over fold  1  =  0.9957924263674615\n",
      "Recall over fold  2  =  0.9992987377279102\n",
      "Recall over fold  3  =  0.9992987377279102\n",
      "Recall over fold  4  =  0.9964961457603364\n",
      "Recall over fold  5  =  0.9971969166082691\n",
      "Recall over fold  6  =  0.9978976874562018\n",
      "Recall over fold  7  =  0.9985974754558204\n"
     ]
    }
   ],
   "source": [
    "pipeNB = Pipeline([('scaler', StandardScaler()), ('nb', GaussianNB())]) #scaling not required i think\n",
    "nb_scores = cross_validate(pipeNB,X,Y,cv=7,return_train_score=True)\n",
    "for i,(score, scoret) in enumerate(zip(nb_scores['test_score'],nb_scores['train_score'])):\n",
    "    print(\"Fold \",i+1)\n",
    "    print(\"Testing Accuracy = \",score,\" Training Accuracy = \",scoret)\n",
    "\n",
    "average['Naive Bayes']=np.average(nb_scores['test_score'])\n",
    "maxm['Naive Bayes']=np.amax(nb_scores['test_score'])\n",
    "print(\"\\nAverage test accuracy= \",average['Naive Bayes'],\"\\n\")\n",
    "\n",
    "nb_prec = cross_validate(pipeNB,X,Y,cv=7,scoring='precision')\n",
    "for i,score in enumerate(nb_prec['test_score']):\n",
    "    print(\"Precision over fold \",i+1,\" = \",score)\n",
    "print(\"\\n\")\n",
    "nb_rec = cross_validate(pipeNB,X,Y,cv=7,scoring='recall')\n",
    "for i,score in enumerate(nb_rec['test_score']):\n",
    "    print(\"Recall over fold \",i+1,\" = \",score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression is a machine learning algorithm for classification. In this algorithm, the probabilities describing the possible outcomes of a single trial are modelled using a logistic function.\n",
    "\n",
    "We import the sklearn LogisticRegression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold  1\n",
      "Testing Accuracy =  0.9880677444187836  Training Accuracy =  0.9890934753320074\n",
      "Fold  2\n",
      "Testing Accuracy =  0.99153194765204  Training Accuracy =  0.9887726951947136\n",
      "Fold  3\n",
      "Testing Accuracy =  0.9923017705927637  Training Accuracy =  0.9887726951947136\n",
      "Fold  4\n",
      "Testing Accuracy =  0.9880677444187836  Training Accuracy =  0.9894142554693014\n",
      "Fold  5\n",
      "Testing Accuracy =  0.9876828329484219  Training Accuracy =  0.9894784114967601\n",
      "Fold  6\n",
      "Testing Accuracy =  0.9880677444187836  Training Accuracy =  0.9894784114967601\n",
      "Fold  7\n",
      "Testing Accuracy =  0.9884482094724683  Training Accuracy =  0.9897356941236849\n",
      "\n",
      "Average test accuracy=  0.9891668562745777 \n",
      "\n",
      "Precision over fold  1  =  0.9840388619014573\n",
      "Precision over fold  2  =  0.9888579387186629\n",
      "Precision over fold  3  =  0.9916083916083916\n",
      "Precision over fold  4  =  0.9847222222222223\n",
      "Precision over fold  5  =  0.9881035689293212\n",
      "Precision over fold  6  =  0.9894810659186536\n",
      "Precision over fold  7  =  0.9867503486750349\n",
      "\n",
      "\n",
      "Recall over fold  1  =  0.9943899018232819\n",
      "Recall over fold  2  =  0.9957924263674615\n",
      "Recall over fold  3  =  0.9943899018232819\n",
      "Recall over fold  4  =  0.9936930623686054\n",
      "Recall over fold  5  =  0.9894884372810091\n",
      "Recall over fold  6  =  0.9887876664330764\n",
      "Recall over fold  7  =  0.9922861150070126\n"
     ]
    }
   ],
   "source": [
    "pipeLR = Pipeline([('scaler', StandardScaler()), ('lr', LogisticRegression(solver='liblinear'))])\n",
    "lr_scores = cross_validate(pipeLR,X,Y,cv=7,return_train_score=True)\n",
    "for i,(score, scoret) in enumerate(zip(lr_scores['test_score'],lr_scores['train_score'])):\n",
    "    print(\"Fold \",i+1)\n",
    "    print(\"Testing Accuracy = \",score,\" Training Accuracy = \",scoret)\n",
    "\n",
    "average['Logistic Regression']=np.average(lr_scores['test_score'])\n",
    "maxm['Logistic Regression']=np.amax(lr_scores['test_score'])\n",
    "print(\"\\nAverage test accuracy= \",average['Logistic Regression'],\"\\n\")\n",
    "\n",
    "lr_prec = cross_validate(pipeLR,X,Y,cv=7,scoring='precision')\n",
    "for i,score in enumerate(lr_prec['test_score']):\n",
    "    print(\"Precision over fold \",i+1,\" = \",score)\n",
    "print(\"\\n\")\n",
    "lr_rec = cross_validate(pipeLR,X,Y,cv=7,scoring='recall')\n",
    "for i,score in enumerate(lr_rec['test_score']):\n",
    "    print(\"Recall over fold \",i+1,\" = \",score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Artificial Neural Network "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Artificial neural network is a machine learning technique used for classification problems. ANN is a set of connected input output network in which weight is associated with each connection. It consists of one input layer, one or more intermediate layer and one output layer.\n",
    "A Multi Layer Perceptron is a supervised learning technique with a feed forward artificial neural network through back-propagation that can classify non-linearly separable data.\n",
    "\n",
    "We import the sklearn MLPClassifier model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold  1\n",
      "Testing Accuracy =  0.9880677444187836  Training Accuracy =  0.9903124398537243\n",
      "Fold  2\n",
      "Testing Accuracy =  0.9911470361816782  Training Accuracy =  0.9903124398537243\n",
      "Fold  3\n",
      "Testing Accuracy =  0.993841416474211  Training Accuracy =  0.9902482838262655\n",
      "Fold  4\n",
      "Testing Accuracy =  0.9880677444187836  Training Accuracy =  0.9907615320459358\n",
      "Fold  5\n",
      "Testing Accuracy =  0.9884526558891455  Training Accuracy =  0.990954000128312\n",
      "Fold  6\n",
      "Testing Accuracy =  0.9884526558891455  Training Accuracy =  0.9913389362930647\n",
      "Fold  7\n",
      "Testing Accuracy =  0.9892183288409704  Training Accuracy =  0.9903772132409546\n",
      "\n",
      "Average test accuracy=  0.989606797444674 \n",
      "\n",
      "Precision over fold  1  =  0.9853963838664812\n",
      "Precision over fold  2  =  0.9888579387186629\n",
      "Precision over fold  3  =  0.9930118798043326\n",
      "Precision over fold  4  =  0.9854166666666667\n",
      "Precision over fold  5  =  0.9888190076869322\n",
      "Precision over fold  6  =  0.9887876664330764\n",
      "Precision over fold  7  =  0.9874913134120917\n",
      "\n",
      "\n",
      "Recall over fold  1  =  0.9936886395511921\n",
      "Recall over fold  2  =  0.9950911640953717\n",
      "Recall over fold  3  =  0.9957924263674615\n",
      "Recall over fold  4  =  0.9936930623686054\n",
      "Recall over fold  5  =  0.9915907498248073\n",
      "Recall over fold  6  =  0.9887876664330764\n",
      "Recall over fold  7  =  0.9943899018232819\n"
     ]
    }
   ],
   "source": [
    "pipeNN = Pipeline([('scaler', StandardScaler()), ('ann', MLPClassifier())])\n",
    "nn_scores = cross_validate(pipeNN,X,Y,cv=7,return_train_score=True)\n",
    "for i,(score, scoret) in enumerate(zip(nn_scores['test_score'],nn_scores['train_score'])):\n",
    "    print(\"Fold \",i+1)\n",
    "    print(\"Testing Accuracy = \",score,\" Training Accuracy = \",scoret)\n",
    "\n",
    "average['Neural Network']=np.average(nn_scores['test_score'])\n",
    "maxm['Neural Network']=np.amax(nn_scores['test_score'])\n",
    "print(\"\\nAverage test accuracy= \",np.average(nn_scores['test_score']),\"\\n\")\n",
    "\n",
    "nn_prec = cross_validate(pipeNN,X,Y,cv=7,scoring='precision')\n",
    "for i,score in enumerate(nn_prec['test_score']):\n",
    "    print(\"Precision over fold \",i+1,\" = \",score)\n",
    "print(\"\\n\")\n",
    "nn_rec = cross_validate(pipeNN,X,Y,cv=7,scoring='recall')\n",
    "for i,score in enumerate(nn_rec['test_score']):\n",
    "    print(\"Recall over fold \",i+1,\" = \",score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support vector machines (SVMs) are a set of supervised learning methods used for classification. They are effective for high dimensional spaces and cases where the number of dimensions is greater than the number of samples.\n",
    "\n",
    "We import the sklearn svm.SVC model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold  1\n",
      "Testing Accuracy =  0.9892224788298691  Training Accuracy =  0.990376595881183\n",
      "Fold  2\n",
      "Testing Accuracy =  0.99153194765204  Training Accuracy =  0.9901199717713479\n",
      "Fold  3\n",
      "Testing Accuracy =  0.9946112394149346  Training Accuracy =  0.9900558157438891\n",
      "Fold  4\n",
      "Testing Accuracy =  0.9884526558891455  Training Accuracy =  0.9907615320459358\n",
      "Fold  5\n",
      "Testing Accuracy =  0.9888375673595073  Training Accuracy =  0.9907615320459358\n",
      "Fold  6\n",
      "Testing Accuracy =  0.9888375673595073  Training Accuracy =  0.990954000128312\n",
      "Fold  7\n",
      "Testing Accuracy =  0.9892183288409704  Training Accuracy =  0.9906338208878624\n",
      "\n",
      "Average test accuracy=  0.9901016836208534 \n",
      "\n",
      "Precision over fold  1  =  0.9860917941585535\n",
      "Precision over fold  2  =  0.9888579387186629\n",
      "Precision over fold  3  =  0.9937062937062937\n",
      "Precision over fold  4  =  0.985406532314107\n",
      "Precision over fold  5  =  0.9888111888111888\n",
      "Precision over fold  6  =  0.9881284916201117\n",
      "Precision over fold  7  =  0.9854166666666667\n",
      "\n",
      "\n",
      "Recall over fold  1  =  0.9943899018232819\n",
      "Recall over fold  2  =  0.9957924263674615\n",
      "Recall over fold  3  =  0.9964936886395512\n",
      "Recall over fold  4  =  0.9936930623686054\n",
      "Recall over fold  5  =  0.9908899789768746\n",
      "Recall over fold  6  =  0.9915907498248073\n",
      "Recall over fold  7  =  0.9950911640953717\n"
     ]
    }
   ],
   "source": [
    "pipesvm = Pipeline([('scaler', StandardScaler()), ('svm', SVC(kernel='rbf'))])  #kernel can linear or rbf or...  rbf gives highest acc\n",
    "svm_scores = cross_validate(pipesvm,X,Y,cv=7,return_train_score=True)\n",
    "for i,(score, scoret) in enumerate(zip(svm_scores['test_score'],svm_scores['train_score'])):\n",
    "    print(\"Fold \",i+1)\n",
    "    print(\"Testing Accuracy = \",score,\" Training Accuracy = \",scoret)\n",
    "    \n",
    "average['SVM']=np.average(svm_scores['test_score'])\n",
    "maxm['SVM']=np.amax(svm_scores['test_score'])\n",
    "print(\"\\nAverage test accuracy= \",average['SVM'],\"\\n\")\n",
    "\n",
    "svm_prec = cross_validate(pipesvm,X,Y,cv=7,scoring='precision')\n",
    "for i,score in enumerate(svm_prec['test_score']):\n",
    "    print(\"Precision over fold \",i+1,\" = \",score)\n",
    "print(\"\\n\")\n",
    "svm_rec = cross_validate(pipesvm,X,Y,cv=7,scoring='recall')\n",
    "for i,score in enumerate(svm_rec['test_score']):\n",
    "    print(\"Recall over fold \",i+1,\" = \",score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boxplots of Testing Accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plot.subplots()\n",
    "ax.boxplot([fda_scores['test_score'],per_scores['test_score'],nb_scores['test_score'],lr_scores['test_score'],nn_scores['test_score'],svm_scores['test_score']])\n",
    "ax.set_xticklabels(['Fisher','Perceptron','NB','Log Regr','ANN','SVM'])\n",
    "plot.ylim([0.97,1.0])\n",
    "plot.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boxplots of Training Accuracies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plot.subplots()\n",
    "ax.boxplot([fda_scores['train_score'],per_scores['train_score'],nb_scores['train_score'],lr_scores['train_score'],nn_scores['train_score'],svm_scores['train_score']])\n",
    "ax.set_xticklabels(['Fisher','Perceptron','NB','Log Regr','ANN','SVM'])\n",
    "plot.ylim([0.94,1.0])\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The average test accuracy over the 7 folds for each classification model shows SVM having the highest accuracy, and Linear Perceptron having the least. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Average Testing Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fisher Discriminant</td>\n",
       "      <td>0.986747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>0.978829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.983723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.989167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Neural Network</td>\n",
       "      <td>0.989607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.990102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Average Testing Accuracy\n",
       "0  Fisher Discriminant                  0.986747\n",
       "1           Perceptron                  0.978829\n",
       "2          Naive Bayes                  0.983723\n",
       "3  Logistic Regression                  0.989167\n",
       "4       Neural Network                  0.989607\n",
       "5                  SVM                  0.990102"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.DataFrame(list(average.items()),columns = ['Model','Average Testing Accuracy']) \n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The maximum test accuracy obtained in a fold for each classification model shows SVM having the highest accuracy, and Naive Bayes having the least."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Maximum Testing Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fisher Discriminant</td>\n",
       "      <td>0.990762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>0.991147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.989607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.992302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Neural Network</td>\n",
       "      <td>0.993841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.994611</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Maximum Testing Accuracy\n",
       "0  Fisher Discriminant                  0.990762\n",
       "1           Perceptron                  0.991147\n",
       "2          Naive Bayes                  0.989607\n",
       "3  Logistic Regression                  0.992302\n",
       "4       Neural Network                  0.993841\n",
       "5                  SVM                  0.994611"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.DataFrame(list(maxm.items()),columns = ['Model','Maximum Testing Accuracy']) \n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The boxplots of the training accuracies show that ANN and SVM perform the best while training the datasets, while NB performs the worst.\n",
    "- Linear Perceptron has the highest variance as shown by its boxplot. This could be due to the fact it makes random predictions of the weights while training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The boxplots of the testing accuracies shows SVM having the highest accuracy with a maximum accuracy of almost 0.995. The ANN model is second with Logistic Regression being the third best.\n",
    "- Linear Perceptron has the lowest accuracy, 0.978, among these models. This could be due to the dataset not being perfectly linearly separable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
