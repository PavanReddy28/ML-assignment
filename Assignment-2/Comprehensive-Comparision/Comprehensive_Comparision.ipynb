{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comprehensive Comparision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plot\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Area</th>\n",
       "      <th>MajorAxisLength</th>\n",
       "      <th>MinorAxisLength</th>\n",
       "      <th>Eccentricity</th>\n",
       "      <th>ConvexArea</th>\n",
       "      <th>EquivDiameter</th>\n",
       "      <th>Extent</th>\n",
       "      <th>Perimeter</th>\n",
       "      <th>Roundness</th>\n",
       "      <th>AspectRation</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4537</td>\n",
       "      <td>92.229317</td>\n",
       "      <td>64.012769</td>\n",
       "      <td>0.719916</td>\n",
       "      <td>4677</td>\n",
       "      <td>76.004525</td>\n",
       "      <td>0.657536</td>\n",
       "      <td>273.085</td>\n",
       "      <td>0.764510</td>\n",
       "      <td>1.440796</td>\n",
       "      <td>jasmine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2872</td>\n",
       "      <td>74.691881</td>\n",
       "      <td>51.400454</td>\n",
       "      <td>0.725553</td>\n",
       "      <td>3015</td>\n",
       "      <td>60.471018</td>\n",
       "      <td>0.713009</td>\n",
       "      <td>208.317</td>\n",
       "      <td>0.831658</td>\n",
       "      <td>1.453137</td>\n",
       "      <td>jasmine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3048</td>\n",
       "      <td>76.293164</td>\n",
       "      <td>52.043491</td>\n",
       "      <td>0.731211</td>\n",
       "      <td>3132</td>\n",
       "      <td>62.296341</td>\n",
       "      <td>0.759153</td>\n",
       "      <td>210.012</td>\n",
       "      <td>0.868434</td>\n",
       "      <td>1.465950</td>\n",
       "      <td>jasmine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3073</td>\n",
       "      <td>77.033628</td>\n",
       "      <td>51.928487</td>\n",
       "      <td>0.738639</td>\n",
       "      <td>3157</td>\n",
       "      <td>62.551300</td>\n",
       "      <td>0.783529</td>\n",
       "      <td>210.657</td>\n",
       "      <td>0.870203</td>\n",
       "      <td>1.483456</td>\n",
       "      <td>jasmine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3693</td>\n",
       "      <td>85.124785</td>\n",
       "      <td>56.374021</td>\n",
       "      <td>0.749282</td>\n",
       "      <td>3802</td>\n",
       "      <td>68.571668</td>\n",
       "      <td>0.769375</td>\n",
       "      <td>230.332</td>\n",
       "      <td>0.874743</td>\n",
       "      <td>1.510000</td>\n",
       "      <td>jasmine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18180</th>\n",
       "      <td>18181</td>\n",
       "      <td>5853</td>\n",
       "      <td>148.624571</td>\n",
       "      <td>51.029281</td>\n",
       "      <td>0.939210</td>\n",
       "      <td>6008</td>\n",
       "      <td>86.326537</td>\n",
       "      <td>0.498594</td>\n",
       "      <td>332.960</td>\n",
       "      <td>0.663444</td>\n",
       "      <td>2.912535</td>\n",
       "      <td>Gonen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18181</th>\n",
       "      <td>18182</td>\n",
       "      <td>7585</td>\n",
       "      <td>169.593996</td>\n",
       "      <td>58.141659</td>\n",
       "      <td>0.939398</td>\n",
       "      <td>7806</td>\n",
       "      <td>98.272692</td>\n",
       "      <td>0.647461</td>\n",
       "      <td>385.506</td>\n",
       "      <td>0.641362</td>\n",
       "      <td>2.916910</td>\n",
       "      <td>Gonen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18182</th>\n",
       "      <td>18183</td>\n",
       "      <td>6365</td>\n",
       "      <td>154.777085</td>\n",
       "      <td>52.908085</td>\n",
       "      <td>0.939760</td>\n",
       "      <td>6531</td>\n",
       "      <td>90.023162</td>\n",
       "      <td>0.561287</td>\n",
       "      <td>342.253</td>\n",
       "      <td>0.682832</td>\n",
       "      <td>2.925396</td>\n",
       "      <td>Gonen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18183</th>\n",
       "      <td>18184</td>\n",
       "      <td>5960</td>\n",
       "      <td>151.397924</td>\n",
       "      <td>51.474600</td>\n",
       "      <td>0.940427</td>\n",
       "      <td>6189</td>\n",
       "      <td>87.112041</td>\n",
       "      <td>0.492399</td>\n",
       "      <td>343.371</td>\n",
       "      <td>0.635227</td>\n",
       "      <td>2.941216</td>\n",
       "      <td>Gonen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18184</th>\n",
       "      <td>18185</td>\n",
       "      <td>6134</td>\n",
       "      <td>153.081981</td>\n",
       "      <td>51.590606</td>\n",
       "      <td>0.941500</td>\n",
       "      <td>6283</td>\n",
       "      <td>88.374495</td>\n",
       "      <td>0.489975</td>\n",
       "      <td>338.613</td>\n",
       "      <td>0.672274</td>\n",
       "      <td>2.967245</td>\n",
       "      <td>Gonen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18185 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  Area  MajorAxisLength  MinorAxisLength  Eccentricity  \\\n",
       "0          1  4537        92.229317        64.012769      0.719916   \n",
       "1          2  2872        74.691881        51.400454      0.725553   \n",
       "2          3  3048        76.293164        52.043491      0.731211   \n",
       "3          4  3073        77.033628        51.928487      0.738639   \n",
       "4          5  3693        85.124785        56.374021      0.749282   \n",
       "...      ...   ...              ...              ...           ...   \n",
       "18180  18181  5853       148.624571        51.029281      0.939210   \n",
       "18181  18182  7585       169.593996        58.141659      0.939398   \n",
       "18182  18183  6365       154.777085        52.908085      0.939760   \n",
       "18183  18184  5960       151.397924        51.474600      0.940427   \n",
       "18184  18185  6134       153.081981        51.590606      0.941500   \n",
       "\n",
       "       ConvexArea  EquivDiameter    Extent  Perimeter  Roundness  \\\n",
       "0            4677      76.004525  0.657536    273.085   0.764510   \n",
       "1            3015      60.471018  0.713009    208.317   0.831658   \n",
       "2            3132      62.296341  0.759153    210.012   0.868434   \n",
       "3            3157      62.551300  0.783529    210.657   0.870203   \n",
       "4            3802      68.571668  0.769375    230.332   0.874743   \n",
       "...           ...            ...       ...        ...        ...   \n",
       "18180        6008      86.326537  0.498594    332.960   0.663444   \n",
       "18181        7806      98.272692  0.647461    385.506   0.641362   \n",
       "18182        6531      90.023162  0.561287    342.253   0.682832   \n",
       "18183        6189      87.112041  0.492399    343.371   0.635227   \n",
       "18184        6283      88.374495  0.489975    338.613   0.672274   \n",
       "\n",
       "       AspectRation    Class  \n",
       "0          1.440796  jasmine  \n",
       "1          1.453137  jasmine  \n",
       "2          1.465950  jasmine  \n",
       "3          1.483456  jasmine  \n",
       "4          1.510000  jasmine  \n",
       "...             ...      ...  \n",
       "18180      2.912535    Gonen  \n",
       "18181      2.916910    Gonen  \n",
       "18182      2.925396    Gonen  \n",
       "18183      2.941216    Gonen  \n",
       "18184      2.967245    Gonen  \n",
       "\n",
       "[18185 rows x 12 columns]"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('dataset_comb.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "jasmine    9985\n",
       "Gonen      8200\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18185, 12)"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Area</th>\n",
       "      <th>MajorAxisLength</th>\n",
       "      <th>MinorAxisLength</th>\n",
       "      <th>Eccentricity</th>\n",
       "      <th>ConvexArea</th>\n",
       "      <th>EquivDiameter</th>\n",
       "      <th>Extent</th>\n",
       "      <th>Perimeter</th>\n",
       "      <th>Roundness</th>\n",
       "      <th>AspectRation</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4537</td>\n",
       "      <td>92.229317</td>\n",
       "      <td>64.012769</td>\n",
       "      <td>0.719916</td>\n",
       "      <td>4677</td>\n",
       "      <td>76.004525</td>\n",
       "      <td>0.657536</td>\n",
       "      <td>273.085</td>\n",
       "      <td>0.764510</td>\n",
       "      <td>1.440796</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2872</td>\n",
       "      <td>74.691881</td>\n",
       "      <td>51.400454</td>\n",
       "      <td>0.725553</td>\n",
       "      <td>3015</td>\n",
       "      <td>60.471018</td>\n",
       "      <td>0.713009</td>\n",
       "      <td>208.317</td>\n",
       "      <td>0.831658</td>\n",
       "      <td>1.453137</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3048</td>\n",
       "      <td>76.293164</td>\n",
       "      <td>52.043491</td>\n",
       "      <td>0.731211</td>\n",
       "      <td>3132</td>\n",
       "      <td>62.296341</td>\n",
       "      <td>0.759153</td>\n",
       "      <td>210.012</td>\n",
       "      <td>0.868434</td>\n",
       "      <td>1.465950</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3073</td>\n",
       "      <td>77.033628</td>\n",
       "      <td>51.928487</td>\n",
       "      <td>0.738639</td>\n",
       "      <td>3157</td>\n",
       "      <td>62.551300</td>\n",
       "      <td>0.783529</td>\n",
       "      <td>210.657</td>\n",
       "      <td>0.870203</td>\n",
       "      <td>1.483456</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3693</td>\n",
       "      <td>85.124785</td>\n",
       "      <td>56.374021</td>\n",
       "      <td>0.749282</td>\n",
       "      <td>3802</td>\n",
       "      <td>68.571668</td>\n",
       "      <td>0.769375</td>\n",
       "      <td>230.332</td>\n",
       "      <td>0.874743</td>\n",
       "      <td>1.510000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  Area  MajorAxisLength  MinorAxisLength  Eccentricity  ConvexArea  \\\n",
       "0   1  4537        92.229317        64.012769      0.719916        4677   \n",
       "1   2  2872        74.691881        51.400454      0.725553        3015   \n",
       "2   3  3048        76.293164        52.043491      0.731211        3132   \n",
       "3   4  3073        77.033628        51.928487      0.738639        3157   \n",
       "4   5  3693        85.124785        56.374021      0.749282        3802   \n",
       "\n",
       "   EquivDiameter    Extent  Perimeter  Roundness  AspectRation  Class  \n",
       "0      76.004525  0.657536    273.085   0.764510      1.440796      1  \n",
       "1      60.471018  0.713009    208.317   0.831658      1.453137      1  \n",
       "2      62.296341  0.759153    210.012   0.868434      1.465950      1  \n",
       "3      62.551300  0.783529    210.657   0.870203      1.483456      1  \n",
       "4      68.571668  0.769375    230.332   0.874743      1.510000      1  "
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "df['Class'] = le.fit_transform(df['Class'])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.values[:,1:-1]\n",
    "Y = df.values[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fisher Linear Discriminant "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold  1\n",
      "Testing Accuracy =  0.8598922247882987  Training Accuracy =  0.9910181561557708\n",
      "Fold  2\n",
      "Testing Accuracy =  0.9992301770592764  Training Accuracy =  0.9861422980689035\n",
      "Fold  3\n",
      "Testing Accuracy =  0.9996150885296382  Training Accuracy =  0.9851799576570219\n",
      "Fold  4\n",
      "Testing Accuracy =  0.9984603541185527  Training Accuracy =  0.9847950214922692\n",
      "Fold  5\n",
      "Testing Accuracy =  0.9980754426481909  Training Accuracy =  0.9840893051902226\n",
      "Fold  6\n",
      "Testing Accuracy =  0.993841416474211  Training Accuracy =  0.9841534612176814\n",
      "Fold  7\n",
      "Testing Accuracy =  0.9068155564112438  Training Accuracy =  0.9967282525019245\n",
      "\n",
      "Average test accuracy=  0.9651328942899161 \n",
      "\n",
      "Precision over fold  1  =  1.0\n",
      "Precision over fold  2  =  0.9992992291520673\n",
      "Precision over fold  3  =  0.9992997198879552\n",
      "Precision over fold  4  =  0.9972027972027973\n",
      "Precision over fold  5  =  0.9965059399021663\n",
      "Precision over fold  6  =  0.9889042995839112\n",
      "Precision over fold  7  =  0.854916067146283\n",
      "\n",
      "\n",
      "Recall over fold  1  =  0.7449194113524877\n",
      "Recall over fold  2  =  0.9992992291520673\n",
      "Recall over fold  3  =  1.0\n",
      "Recall over fold  4  =  1.0\n",
      "Recall over fold  5  =  1.0\n",
      "Recall over fold  6  =  1.0\n",
      "Recall over fold  7  =  1.0\n"
     ]
    }
   ],
   "source": [
    "#pipe = Pipeline([('scaler', MinMaxScaler()), ('fda', LinearDiscriminantAnalysis())]) #scaling not required\n",
    "fda_scores = cross_validate(LinearDiscriminantAnalysis(),X,Y,cv=7,return_train_score=True)\n",
    "for i,(score, scoret) in enumerate(zip(fda_scores['test_score'],fda_scores['train_score'])):\n",
    "    print(\"Fold \",i+1)\n",
    "    print(\"Testing Accuracy = \",score,\" Training Accuracy = \",scoret)\n",
    "    \n",
    "print(\"\\nAverage test accuracy= \",np.average(fda_scores['test_score']),\"\\n\")\n",
    "\n",
    "fda_prec = cross_validate(LinearDiscriminantAnalysis(),X,Y,cv=7,scoring='precision')\n",
    "for i,score in enumerate(fda_prec['test_score']):\n",
    "    print(\"Precision over fold \",i+1,\" = \",score)\n",
    "print(\"\\n\")\n",
    "fda_rec = cross_validate(LinearDiscriminantAnalysis(),X,Y,cv=7,scoring='recall')\n",
    "for i,score in enumerate(fda_rec['test_score']):\n",
    "    print(\"Recall over fold \",i+1,\" = \",score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Perceptron "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold  1\n",
      "Testing Accuracy =  0.5969976905311778  Training Accuracy =  0.9974337589016488\n",
      "Fold  2\n",
      "Testing Accuracy =  0.9992301770592764  Training Accuracy =  0.9769679861422981\n",
      "Fold  3\n",
      "Testing Accuracy =  0.9846035411855273  Training Accuracy =  0.9722845961378072\n",
      "Fold  4\n",
      "Testing Accuracy =  1.0  Training Accuracy =  0.9867197023160326\n",
      "Fold  5\n",
      "Testing Accuracy =  1.0  Training Accuracy =  0.9831911208057997\n",
      "Fold  6\n",
      "Testing Accuracy =  0.99153194765204  Training Accuracy =  0.9803040995701546\n",
      "Fold  7\n",
      "Testing Accuracy =  0.9306892568348094  Training Accuracy =  0.9961508852963818\n",
      "\n",
      "Average test accuracy=  0.9290075161804044 \n",
      "\n",
      "Precision over fold  1  =  1.0\n",
      "Precision over fold  2  =  1.0\n",
      "Precision over fold  3  =  0.9894142554693014\n",
      "Precision over fold  4  =  1.0\n",
      "Precision over fold  5  =  1.0\n",
      "Precision over fold  6  =  0.9848066298342542\n",
      "Precision over fold  7  =  0.887920298879203\n",
      "\n",
      "\n",
      "Recall over fold  1  =  0.2662929222144359\n",
      "Recall over fold  2  =  0.9985984583041345\n",
      "Recall over fold  3  =  0.9824807288016818\n",
      "Recall over fold  4  =  1.0\n",
      "Recall over fold  5  =  1.0\n",
      "Recall over fold  6  =  1.0\n",
      "Recall over fold  7  =  1.0\n"
     ]
    }
   ],
   "source": [
    "pipeLP = Pipeline([('scaler', StandardScaler()), ('per', Perceptron())])  #or use MinMaxScaler\n",
    "per_scores = cross_validate(pipeLP,X,Y,cv=7,return_train_score=True)\n",
    "for i,(score, scoret) in enumerate(zip(per_scores['test_score'],per_scores['train_score'])):\n",
    "    print(\"Fold \",i+1)\n",
    "    print(\"Testing Accuracy = \",score,\" Training Accuracy = \",scoret)\n",
    "\n",
    "print(\"\\nAverage test accuracy= \",np.average(per_scores['test_score']),\"\\n\")\n",
    "\n",
    "per_prec = cross_validate(pipeLP,X,Y,cv=7,scoring='precision')\n",
    "for i,score in enumerate(per_prec['test_score']):\n",
    "    print(\"Precision over fold \",i+1,\" = \",score)\n",
    "print(\"\\n\")\n",
    "per_rec = cross_validate(pipeLP,X,Y,cv=7,scoring='recall')\n",
    "for i,score in enumerate(per_rec['test_score']):\n",
    "    print(\"Recall over fold \",i+1,\" = \",score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold  1\n",
      "Testing Accuracy =  0.9830638953040801  Training Accuracy =  0.9821004683390004\n",
      "Fold  2\n",
      "Testing Accuracy =  0.9892224788298691  Training Accuracy =  0.9763264258677102\n",
      "Fold  3\n",
      "Testing Accuracy =  0.9930715935334873  Training Accuracy =  0.9751074613459935\n",
      "Fold  4\n",
      "Testing Accuracy =  0.9896073903002309  Training Accuracy =  0.9751074613459935\n",
      "Fold  5\n",
      "Testing Accuracy =  0.9865280985373364  Training Accuracy =  0.974658369153782\n",
      "Fold  6\n",
      "Testing Accuracy =  0.9819091608929946  Training Accuracy =  0.9747866812086996\n",
      "Fold  7\n",
      "Testing Accuracy =  0.9129765113592607  Training Accuracy =  0.9862714908904285\n",
      "\n",
      "Average test accuracy=  0.9766255898224657 \n",
      "\n",
      "Precision over fold  1  =  0.9900779588944011\n",
      "Precision over fold  2  =  0.981417756366139\n",
      "Precision over fold  3  =  0.9875432525951557\n",
      "Precision over fold  4  =  0.981417756366139\n",
      "Precision over fold  5  =  0.9760438056125941\n",
      "Precision over fold  6  =  0.9680923285811269\n",
      "Precision over fold  7  =  0.8631961259079903\n",
      "\n",
      "\n",
      "Recall over fold  1  =  0.9789768745620182\n",
      "Recall over fold  2  =  0.9992992291520673\n",
      "Recall over fold  3  =  1.0\n",
      "Recall over fold  4  =  1.0\n",
      "Recall over fold  5  =  1.0\n",
      "Recall over fold  6  =  1.0\n",
      "Recall over fold  7  =  1.0\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([('scaler', StandardScaler()), ('nb', GaussianNB())]) #scaling not required i think\n",
    "nb_scores = cross_validate(GaussianNB(),X,Y,cv=7,return_train_score=True)\n",
    "for i,(score, scoret) in enumerate(zip(nb_scores['test_score'],nb_scores['train_score'])):\n",
    "    print(\"Fold \",i+1)\n",
    "    print(\"Testing Accuracy = \",score,\" Training Accuracy = \",scoret)\n",
    "\n",
    "print(\"\\nAverage test accuracy= \",np.average(nb_scores['test_score']),\"\\n\")\n",
    "\n",
    "nb_prec = cross_validate(GaussianNB(),X,Y,cv=7,scoring='precision')\n",
    "for i,score in enumerate(nb_prec['test_score']):\n",
    "    print(\"Precision over fold \",i+1,\" = \",score)\n",
    "print(\"\\n\")\n",
    "nb_rec = cross_validate(GaussianNB(),X,Y,cv=7,scoring='recall')\n",
    "for i,score in enumerate(nb_rec['test_score']):\n",
    "    print(\"Recall over fold \",i+1,\" = \",score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold  1\n",
      "Testing Accuracy =  0.7809853733641262  Training Accuracy =  0.9957015461602617\n",
      "Fold  2\n",
      "Testing Accuracy =  0.9996150885296382  Training Accuracy =  0.9846667094373517\n",
      "Fold  3\n",
      "Testing Accuracy =  0.9992301770592764  Training Accuracy =  0.9847308654648104\n",
      "Fold  4\n",
      "Testing Accuracy =  0.9980754426481909  Training Accuracy =  0.9846667094373517\n",
      "Fold  5\n",
      "Testing Accuracy =  0.9988452655889145  Training Accuracy =  0.9844742413549753\n",
      "Fold  6\n",
      "Testing Accuracy =  0.993841416474211  Training Accuracy =  0.9853082697119394\n",
      "Fold  7\n",
      "Testing Accuracy =  0.9241432422025414  Training Accuracy =  0.9939055683859379\n",
      "\n",
      "Average test accuracy=  0.9563908579809856 \n",
      "\n",
      "Precision over fold  1  =  1.0\n",
      "Precision over fold  2  =  1.0\n",
      "Precision over fold  3  =  0.9986004198740378\n",
      "Precision over fold  4  =  0.9965059399021663\n",
      "Precision over fold  5  =  0.9979006298110566\n",
      "Precision over fold  6  =  0.9889042995839112\n",
      "Precision over fold  7  =  0.8786198398028343\n",
      "\n",
      "\n",
      "Recall over fold  1  =  0.6012613875262789\n",
      "Recall over fold  2  =  0.9992992291520673\n",
      "Recall over fold  3  =  1.0\n",
      "Recall over fold  4  =  1.0\n",
      "Recall over fold  5  =  1.0\n",
      "Recall over fold  6  =  1.0\n",
      "Recall over fold  7  =  1.0\n"
     ]
    }
   ],
   "source": [
    "pipeLR = Pipeline([('scaler', MinMaxScaler()), ('lr', LogisticRegression(solver='liblinear'))])\n",
    "lr_scores = cross_validate(pipeLR,X,Y,cv=7,return_train_score=True)\n",
    "for i,(score, scoret) in enumerate(zip(lr_scores['test_score'],lr_scores['train_score'])):\n",
    "    print(\"Fold \",i+1)\n",
    "    print(\"Testing Accuracy = \",score,\" Training Accuracy = \",scoret)\n",
    "\n",
    "print(\"\\nAverage test accuracy= \",np.average(lr_scores['test_score']),\"\\n\")\n",
    "\n",
    "lr_prec = cross_validate(pipeLR,X,Y,cv=7,scoring='precision')\n",
    "for i,score in enumerate(lr_prec['test_score']):\n",
    "    print(\"Precision over fold \",i+1,\" = \",score)\n",
    "print(\"\\n\")\n",
    "lr_rec = cross_validate(pipeLR,X,Y,cv=7,scoring='recall')\n",
    "for i,score in enumerate(lr_rec['test_score']):\n",
    "    print(\"Recall over fold \",i+1,\" = \",score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Artificial Neural Network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold  1\n",
      "Testing Accuracy =  0.6285604311008468  Training Accuracy =  0.9976903830114839\n",
      "Fold  2\n",
      "Testing Accuracy =  0.9980754426481909  Training Accuracy =  0.9891576313594662\n",
      "Fold  3\n",
      "Testing Accuracy =  0.9992301770592764  Training Accuracy =  0.9890293193045486\n",
      "Fold  4\n",
      "Testing Accuracy =  0.9992301770592764  Training Accuracy =  0.9894784114967601\n",
      "Fold  5\n",
      "Testing Accuracy =  0.9996150885296382  Training Accuracy =  0.9887726951947136\n",
      "Fold  6\n",
      "Testing Accuracy =  0.9980754426481909  Training Accuracy =  0.9894142554693014\n",
      "Fold  7\n",
      "Testing Accuracy =  0.8806314978821718  Training Accuracy =  0.9974980754426482\n",
      "\n",
      "Average test accuracy=  0.929059750989656 \n",
      "\n",
      "Precision over fold  1  =  1.0\n",
      "Precision over fold  2  =  0.9978976874562018\n",
      "Precision over fold  3  =  0.9992997198879552\n",
      "Precision over fold  4  =  0.9985994397759104\n",
      "Precision over fold  5  =  0.9992992291520673\n",
      "Precision over fold  6  =  0.9944211994421199\n",
      "Precision over fold  7  =  0.8200115008625647\n",
      "\n",
      "\n",
      "Recall over fold  1  =  0.36229852838121934\n",
      "Recall over fold  2  =  0.9985984583041345\n",
      "Recall over fold  3  =  1.0\n",
      "Recall over fold  4  =  1.0\n",
      "Recall over fold  5  =  1.0\n",
      "Recall over fold  6  =  1.0\n",
      "Recall over fold  7  =  1.0\n"
     ]
    }
   ],
   "source": [
    "pipeNN = Pipeline([('scaler', StandardScaler()), ('ann', MLPClassifier())])\n",
    "nn_scores = cross_validate(pipeNN,X,Y,cv=7,return_train_score=True)\n",
    "for i,(score, scoret) in enumerate(zip(nn_scores['test_score'],nn_scores['train_score'])):\n",
    "    print(\"Fold \",i+1)\n",
    "    print(\"Testing Accuracy = \",score,\" Training Accuracy = \",scoret)\n",
    "\n",
    "print(\"\\nAverage test accuracy= \",np.average(nn_scores['test_score']),\"\\n\")\n",
    "\n",
    "nn_prec = cross_validate(pipeNN,X,Y,cv=7,scoring='precision')\n",
    "for i,score in enumerate(nn_prec['test_score']):\n",
    "    print(\"Precision over fold \",i+1,\" = \",score)\n",
    "print(\"\\n\")\n",
    "nn_rec = cross_validate(pipeNN,X,Y,cv=7,scoring='recall')\n",
    "for i,score in enumerate(nn_rec['test_score']):\n",
    "    print(\"Recall over fold \",i+1,\" = \",score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold  1\n",
      "Testing Accuracy =  0.7802155504234026  Training Accuracy =  0.996792198627061\n",
      "Fold  2\n",
      "Testing Accuracy =  1.0  Training Accuracy =  0.9889010072496311\n",
      "Fold  3\n",
      "Testing Accuracy =  0.9996150885296382  Training Accuracy =  0.9889010072496311\n",
      "Fold  4\n",
      "Testing Accuracy =  0.9992301770592764  Training Accuracy =  0.989221787386925\n",
      "Fold  5\n",
      "Testing Accuracy =  0.9996150885296382  Training Accuracy =  0.9890934753320074\n",
      "Fold  6\n",
      "Testing Accuracy =  0.9976905311778291  Training Accuracy =  0.9891576313594662\n",
      "Fold  7\n",
      "Testing Accuracy =  0.8860223334616866  Training Accuracy =  0.9974980754426482\n",
      "\n",
      "Average test accuracy=  0.9517698241687816 \n",
      "\n",
      "Precision over fold  1  =  0.9314516129032258\n",
      "Precision over fold  2  =  1.0\n",
      "Precision over fold  3  =  0.9992997198879552\n",
      "Precision over fold  4  =  0.9985994397759104\n",
      "Precision over fold  5  =  0.9992992291520673\n",
      "Precision over fold  6  =  0.9958100558659218\n",
      "Precision over fold  7  =  0.8281068524970964\n",
      "\n",
      "\n",
      "Recall over fold  1  =  0.6475122634898388\n",
      "Recall over fold  2  =  1.0\n",
      "Recall over fold  3  =  1.0\n",
      "Recall over fold  4  =  1.0\n",
      "Recall over fold  5  =  1.0\n",
      "Recall over fold  6  =  1.0\n",
      "Recall over fold  7  =  1.0\n"
     ]
    }
   ],
   "source": [
    "pipesvm = Pipeline([('scaler', StandardScaler()), ('svm', SVC(kernel='rbf'))])  #kernel can linear or rbf or...  rbf gives highest acc\n",
    "svm_scores = cross_validate(pipesvm,X,Y,cv=7,return_train_score=True)\n",
    "for i,(score, scoret) in enumerate(zip(svm_scores['test_score'],svm_scores['train_score'])):\n",
    "    print(\"Fold \",i+1)\n",
    "    print(\"Testing Accuracy = \",score,\" Training Accuracy = \",scoret)\n",
    "\n",
    "print(\"\\nAverage test accuracy= \",np.average(svm_scores['test_score']),\"\\n\")\n",
    "\n",
    "svm_prec = cross_validate(pipesvm,X,Y,cv=7,scoring='precision')\n",
    "for i,score in enumerate(svm_prec['test_score']):\n",
    "    print(\"Precision over fold \",i+1,\" = \",score)\n",
    "print(\"\\n\")\n",
    "svm_rec = cross_validate(pipesvm,X,Y,cv=7,scoring='recall')\n",
    "for i,score in enumerate(svm_rec['test_score']):\n",
    "    print(\"Recall over fold \",i+1,\" = \",score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plot.subplots()\n",
    "ax.boxplot([fda_scores['test_score'],per_scores['test_score'],nb_scores['test_score'],lr_scores['test_score'],nn_scores['test_score'],svm_scores['test_score']])\n",
    "ax.set_xticklabels(['Fisher','Perceptron','NB','Log Regr','ANN','SVM'])\n",
    "#plot.ylim([0.9,1.01])\n",
    "plot.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Accuracies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD4CAYAAADlwTGnAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAYuklEQVR4nO3df5Ac5X3n8fcna2FZYJsVLJSCkERhxVllwTp7Iwzm7FPwJUAcC7ATS7kEzC3GXEUyJo7rFDZXli8RFrYpTNkYSj4Ro0vdyj91UVw5fhSRUfZiDCtYhITAFgiDQIVFtIecMwRJ970/+lnUGlba2dXszM48n1fV1M50P93P88zMzqf76ZluRQRmZpafX2l0A8zMrDEcAGZmmXIAmJllygFgZpYpB4CZWabe1OgGjMXJJ58cc+bMaXQzzMyayubNm1+KiI7K6U0VAHPmzGFgYKDRzTAzayqSfjbSdA8BmZllygFgZpYpB4CZWaYcAGZmmXIAmJllygFgZpYpB4CZWaYcAGZmmWqqH4KZWeuQNO5lfR2T2nAAmFlDHO1DXJI/5OvAAdDivJVl1hjN8L/nAGhx3soya4xm+N/zQWAzs0w5AEbQ19dHV1cXbW1tdHV10dfX1+gmmZnVnIeAKvT19dHb28uaNWs4//zz6e/vp6enB4AlS5Y0uHWWk2YYQ7bmpmZ6o3R3d8dEXw+gq6uLr371qyxcuPD1aRs3bmTZsmVs3bp1Quuut8kyDmlj1+qvnftX8/o2R0T3G6Y305NcjwBoa2vj1VdfZcqUKa9P279/P1OnTuXgwYMTWne9tfo/WStr9dfO/at5fSMGgI8BVOjs7KS/v/+waf39/XR2djaoRWZmE8MBUKG3t5eenh42btzI/v372bhxIz09PfT29ja6aWZmNeWDwBWGD/QuW7aM7du309nZycqVK30A2Mxajo8BZKzVx1lbWau/du5fzevzMQAzMzvEAWBmlikHgJlZphwAZmaZcgCYmWWqqgCQdKGkJyXtkLR8hPntktZL2iLpQUldpXnXStoqaZukT5emr5D0vKTBdLu4Jj0yM7OqjBoAktqAW4GLgHnAEknzKopdDwxGxNnA5cAtadku4BPAAuBdwIckzS0td3NEzE+3vz/m3piZWdWq2QNYAOyIiKcj4jVgHbCoosw84D6AiHgCmCPpVKATeCAifhkRB4D7gUtr1nozMxu3agLgNOC50uNdaVrZo8BlAJIWALOBmcBW4P2STpI0DbgYOL203NI0bHSHpPaRKpd0taQBSQN79uypqlNmZja6agJgpJOSV/6EbRXQLmkQWAY8AhyIiO3AjcC9wF0UQXEgLXMbcCYwH9gN3DRS5RGxOiK6I6K7o6OjiuaamVk1qjkX0C4O32qfCbxQLhAR+4ArAVRcxWJnuhERa4A1ad4NaX1ExIvDy0v6BvCD8XbCzMzGrpo9gIeAuZLOkHQcsBjYUC4g6cQ0D+AqYFMKBSSdkv7Oohgm6kuPZ5RWcSnFcJGZmdXJqHsAEXFA0lLgbqANuCMitkm6Js2/neJg71pJB4HHgZ7SKr4n6SRgP/AnETGUpn9R0nyK4aRngE/WpktmZlYNnw00Y61+xsVW1uqvnftX8/p8NlAzMzvEAWBmlikHgJlZphwAZmaZcgCYmWXKAWBmlikHgJlNmOnTpyNpzDdgXMtNnz69wT1uLtWcCsLMbFyGhobq/X33utXVCrwHYGaWKQeAmVmmHABmZuPU7Mc4fAzAzGycmv0Yh/cAzMwy5QAwM8uUA8DMLFMOADOzTDkAzMwy5QAwM8uUA8CsgZr9e+TW3Pw7ALMGavbvkVtz8x6AmVmmHABmZplyALQAjyOb2Xj4GEAL8DiymY2H9wDMzDKV/R7AsWzN1nOr28ys1rIPgKN9iEvyh7yZtSwPAZmZZcoBYGaWKQeAmVmmqgoASRdKelLSDknLR5jfLmm9pC2SHpTUVZp3raStkrZJ+nRp+nRJ90r6afrbXpMemZlZVUYNAEltwK3ARcA8YImkeRXFrgcGI+Js4HLglrRsF/AJYAHwLuBDkuamZZYD90XEXOC+9NjMzOqkmj2ABcCOiHg6Il4D1gGLKsrMo/gQJyKeAOZIOhXoBB6IiF9GxAHgfuDStMwi4M50/07gkmPpiJmZjU01AXAa8Fzp8a40rexR4DIASQuA2cBMYCvwfkknSZoGXAycnpY5NSJ2A6S/p4xUuaSrJQ1IGtizZ091vTIzs1FVEwAj/VKq8svxq4B2SYPAMuAR4EBEbAduBO4F7qIIigNjaWBErI6I7ojo7ujoGMuiZmZ2FNX8EGwXh7baodiyf6FcICL2AVcCqPhp7c50IyLWAGvSvBvS+gBelDQjInZLmgH8/Bj6YWZmY1TNHsBDwFxJZ0g6DlgMbCgXkHRimgdwFbAphQKSTkl/Z1EME/WlchuAK9L9K4C/PZaOmJnZ2Iy6BxARByQtBe4G2oA7ImKbpGvS/NspDvaulXQQeBzoKa3ie5JOAvYDfxIRQ2n6KuDbknqAZ4Hfr1WnzMxsdGqmc910d3fHwMBA3eprlnMB1budzfK8NIOWf+1WvL1+db1e58t1q6pZXj9JmyOiu3J69ieDM7OJo8/vq/8H5Iq6Vdf0HABmNqHqeQGh9vb6nlAgPve2uu7lxOfeVtP1OQDMbMKMd+u/WYYZ9fl9da2vvb2dvStqtz4HgJnZOI12PZGJWG8tOQDMrCFG+4A82vxm2DtohjZmEQDTp09naGho9IIjGE+Kt7e3s3fv3nHVZ5aLZviAbHVZBMDQ0FDdv4lgZjbZ+YIwZmaZcgCYmWXKAWBmlikHgJlZphwAZmaZcgCYmWUqi6+Bmk1WzX4uGWtuDgCzBvLZMq2RHABmDdbKZ8u0yc0BYNZArX62TJvcHABmk1SrnyzNGs8BYDZJ+UPcJpq/BmpmlikHgLWUvr4+urq6aGtro6uri76+vkY3yWzS8hCQtYy+vj56e3tZs2YN559/Pv39/fT09ACwZMmSBrfObPLxHoC1jJUrV7JmzRoWLlzIlClTWLhwIWvWrGHlypWNbprZpKRmOtDU3d0dAwMDY16u3l+Zc32N0dbWxquvvsqUKVNen7Z//36mTp3KwYMHG9gys8aStDkiuiunew/AWkZnZyf9/f2HTevv76ezs7NBLTKb3BwA1jJ6e3vp6elh48aN7N+/n40bN9LT00Nvb2+jm2Y2KfkgsLWM4QO9y5YtY/v27XR2drJy5UofADY7Ah8DmACuz8wmEx8DMDOzwzgAzMwyVVUASLpQ0pOSdkhaPsL8dknrJW2R9KCkrtK86yRtk7RVUp+kqWn6CknPSxpMt4tr1y0zMxvNqAEgqQ24FbgImAcskTSvotj1wGBEnA1cDtySlj0N+BTQHRFdQBuwuLTczRExP93+/ph7Y2ZmVavmW0ALgB0R8TSApHXAIuDxUpl5wBcAIuIJSXMknVqq4y2S9gPTgBdq1fhq+bJ7ZmZvVE0AnAY8V3q8CzinosyjwGVAv6QFwGxgZkRslvRl4FngFeCeiLintNxSSZcDA8BnImKosnJJVwNXA8yaNau6XlWuw5fdMzN7g2qOAYx01YnKT9NVQLukQWAZ8AhwQFI7xd7CGcCvAsdL+qO0zG3AmcB8YDdw00iVR8TqiOiOiO6Ojo4qmmtmZtWoZg9gF3B66fFMKoZxImIfcCWAissU7Uy33wF2RsSeNO/7wHnA30TEi8PLS/oG8IPxd8PMzMaqmj2Ah4C5ks6QdBzFQdwN5QKSTkzzAK4CNqVQeBZ4r6RpKRguALanZWaUVnEpsPXYumJmZmMx6h5ARByQtBS4m+JbPHdExDZJ16T5twOdwFpJBykODvekeT+W9F3gYeAAxdDQ6rTqL0qaTzGc9AzwyRr26w1Gu75qLbW3t9etLjOz8criVBDj1SynPPCpIMzsaHwqCDMzO0z2ZwMdbWjoaPO9FWxmzSz7APCHuJnlykNAZmaZcgCYmWXKAWBmlikHgJlZphwAZmaZyv5bQK3Ap7s2s/FwALQAn+7azMbDQ0BmZplyAJiZZcoBYGaWKQeAmVmmHABmZplyAJiZZcoBYGaWKf8OwJrWsVzm06cBN3MAWBM72oe4L1tpNjoPAZmZZcoBYGaWKQeAmVmmHABmZplyAJiZZcoBYGaWKQeAmVmmHABmZplyAJiZZcoBYGaWKQeAmVmmqgoASRdKelLSDknLR5jfLmm9pC2SHpTUVZp3naRtkrZK6pM0NU2fLuleST9Nf9tr1y0zMxvNqAEgqQ24FbgImAcskTSvotj1wGBEnA1cDtySlj0N+BTQHRFdQBuwOC2zHLgvIuYC96XHZmZWJ9XsASwAdkTE0xHxGrAOWFRRZh7FhzgR8QQwR9Kpad6bgLdIehMwDXghTV8E3Jnu3wlcMt5OmJnZ2FUTAKcBz5Ue70rTyh4FLgOQtACYDcyMiOeBLwPPAruBlyPinrTMqRGxGyD9PWWkyiVdLWlA0sCePXuq65WZmY2qmgAY6aoblSdaXwW0SxoElgGPAAfSuP4i4AzgV4HjJf3RWBoYEasjojsiujs6OsayqJmZHUU1F4TZBZxeejyTQ8M4AETEPuBKABWXadqZbr8D7IyIPWne94HzgL8BXpQ0IyJ2S5oB/PwY+2JmZmNQzR7AQ8BcSWdIOo7iIO6GcgFJJ6Z5AFcBm1IoPAu8V9K0FAwXANtTuQ3AFen+FcDfHltXzMxsLEbdA4iIA5KWAndTfIvnjojYJumaNP92oBNYK+kg8DjQk+b9WNJ3gYeBAxRDQ6vTqlcB35bUQxEUv1/TnpmZ2VGpma6b2t3dHQMDA41uxqRT7+vfNsP1dpuhjWb1ImlzRHRXTvcvgW3Smz59OpLGdAPGvIwkpk+f3uDemtVPNQeBzRpqaGioblvzw+FhlgPvAZiZZcoBYGaWKQ8BtYh6Dl20t/u8fWatwAHQAsY7Pu5vypjlzUNAZmaZcgCYmWXKAWBmlikHgJlZphwAZmaZcgCYmWXKAWBmlikHgJlZphwAZmaZcgCYmWXKAWBmlikHgJlZphwAZmaZcgCYmWXKAWBmlikHgJlZphwAZmaZcgCYmWXKAWBmlikHgJlZphwAZmaZcgCYmWXKAWBmlikHgJlZpqoKAEkXSnpS0g5Jy0eY3y5pvaQtkh6U1JWmv1PSYOm2T9Kn07wVkp4vzbu4pj0zM7OjetNoBSS1AbcC/x7YBTwkaUNEPF4qdj0wGBGXSvr1VP6CiHgSmF9az/PA+tJyN0fEl2vSEzMzG5NRAwBYAOyIiKcBJK0DFgHlAJgHfAEgIp6QNEfSqRHxYqnMBcBTEfGz2jTdchGfexuseHv96jLLRDUBcBrwXOnxLuCcijKPApcB/ZIWALOBmUA5ABYDfRXLLZV0OTAAfCYihiorl3Q1cDXArFmzqmiutRp9fl/d6mpvb2fvirpVZ9ZQ1RwD0AjTouLxKqBd0iCwDHgEOPD6CqTjgA8D3yktcxtwJsUQ0W7gppEqj4jVEdEdEd0dHR1VNNdaTUSM+Tbe5fbu3dvg3prVTzV7ALuA00uPZwIvlAtExD7gSgBJAnam27CLgIfLQ0Ll+5K+AfxgrI23vBVvtfHNHw4Js5xVswfwEDBX0hlpS34xsKFcQNKJaR7AVcCmFArDllAx/CNpRunhpcDWsTbe8jaeLfzyHoJZ7kbdA4iIA5KWAncDbcAdEbFN0jVp/u1AJ7BW0kGKg8M9w8tLmkbxDaJPVqz6i5LmUwwnPTPCfDMzm0Bqpq2h7u7uGBgYaHQzWoYkbw2bZUDS5ojorpzuXwKbmWXKAWBmlikHgJlZphwAZmaZcgCYmWXKAWBmlikHgJlZphwAZmaZcgCYmWXKAWBmlikHgJlZphwAZmaZcgCYmWXKAWBmlikHgJlZpqq5JKQ1MV820cyOxAHQ4vwhbmZH4iEgM7NMOQDMzDLlADAzy5QDwMwsUw4AM7NMOQDMzDLlADAzy5QDwMwsU2qmHwpJ2gP8rI5Vngy8VMf66q2V+9fKfQP3r9nVu3+zI6KjcmJTBUC9SRqIiO5Gt2OitHL/Wrlv4P41u8nSPw8BmZllygFgZpYpB8DRrW50AyZYK/evlfsG7l+zmxT98zEAM7NMeQ/AzCxTDgAzs0xlEQCSDkoaLN3mSPqnUZb5l3q1b4S6h9u7VdJ3JE1rQBsukTSv3vWOlaSQdFPp8Z9JWpHur5D0fHoun5B0m6S6v+dr/V5K799XUr8el7RW0pRa1jGRJF2aXrdfT4/npMfLSmW+Junj6f430+v45vT4ZEnPNKLt1ZDUK2mbpC3pNfpfkr5QUWa+pO3p/jOS/rFi/qCkrRPd1iwCAHglIuaXbs9ExHkTVZmkY73S2nB7u4DXgGvqVG/ZJcCIAVDjeo7VvwKXSTr5CPNvjoj5FH05C/hAvRo2wZ5K/ToLmAn8wbGusI6v6xKgH1hcmvZz4FpJxx1hmYPAf5zohh0rSecCHwLeHRFnAx8EVgEfqyi6GPgfpcdvlXR6WkdnPdoK+QTAGwxvlUmaIWlTaYv735bKrJT0qKQHJJ2apnVI+p6kh9LtfWn6CkmrJd0DrK1hU/8ReIek4yXdkep8RNKiVO/H017C3wH3SDpB0l9LeixtgXwklfttST+S9HAqf0Ka/oykGyU9mG7vkHQe8GHgS+l5OVPSDyXdIOl+in/UC1I7HkvtenNpfZ9P9Tw2vJU3gQ5QfKPiulHKHQdMBYYmuD1VSVuAD6TXaL2k9jT9N9O0H0n60mhbgRFxEHgQOC0t/x5J90vaLOluSTOOtt7K98+Edrqo7wTgfUAPhwfAHuA+4IojLPoV4LpJtvExkhnASxHxrwAR8VJE3A/8H0nnlMr9AbCu9PjbHAqJJUBfPRqbSwC8RYeGf9ZXzPtD4O60NfUuYDBNPx54ICLeBWwCPpGm30KxVfmbwEeA/1Za13uARRHxh7VodHqzXwQ8BvQC/5DqXUjx4Xx8KnoucEVE/BbwX4CXI+KstAXyD2nr+C+AD0bEu4EB4E9LVe2LiAXA14CvRMQ/ARuAz6Y9kadSuRMj4gPArcA3gY9FxFkU15b+T6X1vZTquQ34s1o8F6O4FfgPkt4+wrzrJA0Cu4GfRMRgHdpTjbXAf06v0WPA59L0vwauiYhzKbZ6j0rSVOAc4C4Vw0BfBT4aEe8B7gBWVrHe8vtnol0C3BURPwH2Snp3ad4q4DOS2kZY7lmKvYY/nvgmHpN7gNMl/UTS1yUN73H2kQJP0nuBf46In5aW+y5wWbr/e8Df1aOxuQRAeQjo0op5DwFXqhg3PisifpGmvwb8IN3fDMxJ9z8IfC19qGwA3ibprWnehoh4pQbtfUta/wDFG38N8NvA8jT9hxRbs7NS+XsjYm+pfbcOrygihoD3UgyB/O+0/BXA7FJ9faW/5x6lXd9Kf98J7Ez/xAB3Au8vlft++lt+3iZMROyj+ED91Aizh4eATgGOl7R4hDJ1lYLqxLRlCOn5k3Qi8NYUwHD4EEGlM9Nr+c/AsxGxheJ16QLuTfP+AphZxXrL75+JtoRDW77r0mMAImInxd7MkTagbgA+yyT+3IqIf6HYELyaYq/mWyqOZawDPqriGNRi3riFvxcYSu/P7cAv69Heyb47NeEiYpOk9wO/C/x3SV+KiLXA/jj0I4mDHHqufgU4t/KDXhLA/61Rs15JH1rl9Qv4SEQ8WTH9nIp6BVT+uEMU/+RLGFkc4X6l4Xp0lDJQjMvD4c/bRPsK8DDFlu4bRMR+SXdRBNW6kcpMAqM9r2VPRcT8NMTzQ0kfBnYC29JW/qGVpuGlo6jV+/aoJJ0E/BbQJSmANor329dLxW6g2BreVLl8ROxIwXbMxzsmUhqW+yHF6/IYxd7VN1UcuP4AxcjBSBta36LYePt4fVo6iZO0XiTNBn4eEd+g2NJ+9yiL3AMsLS0/f+Jad5i7gWUpCJD0b45QrrJ97cADwPskvSNNmybp10rLfKz090fp/i+AtzKyJ4A5w+uj2C2//whl6yJtwX6bYmz5DdLzdh7w1Ejz6ykiXqbY2hs+3vTHwP1pb+0XaYgADh8jP9K6dgPLgT8HngQ6VByIRNIUSb8xnvVOkI8CayNidkTMiYjTKUJr5nCBiHgCeJziQOpIVlKfYcVxkfROSXNLk+Zz6AzGfcDNFOG9a4TF1wNfpPhfr4vsAwD4d8CgpEcokvmWUcp/CuhOB9Qep8pv6NTAXwJTgC3pAN5fHqHcXwHtKg5oPwosjIg9FFsVfZK2UARC+eDsmyX9GLiWQwdT1wGfTQd6zyxXEBGvAlcC30lbOP8PuL0WnTxGN1GcZrds+BjAVoq9ka9XLlQH0yTtKt3+lGIY7kvp9ZgP/NdUtgdYLelHFHsEL1ex/v8JTKM4FvBR4Mb02g9ShN5411trSyg+5Mq+B1xfMW0lpVAoi4htFHt6k9UJwJ0qvp67hWLodUWa9x3gNzjCHmhE/CIiboyI1+rSUnwqiOyl3dLuiGjlc683DUknpHFkJC0HZkTEtZN1vdbcsj8GYDbJ/K6kP6f43/wZtRsPnqj1WhPzHoCZWaZ8DMDMLFMOADOzTDkAzMwy5QAwM8uUA8DMLFP/HweFPB2MSJf8AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plot.subplots()\n",
    "ax.boxplot([fda_scores['train_score'],per_scores['train_score'],nb_scores['train_score'],lr_scores['train_score'],nn_scores['train_score'],svm_scores['train_score']])\n",
    "ax.set_xticklabels(['Fisher','Perceptron','NB','Log Regr','ANN','SVM'])\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
