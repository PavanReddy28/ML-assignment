{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comprehensive Comparision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do a comparative study and analysis of the following Machine Learning models-\n",
    "- Fisher Linear Discriminant\n",
    "- Linear Perceptron\n",
    "- Naive Bayes\n",
    "- Logistic Regression\n",
    "- Artificial Neural Networks and,\n",
    "- Support Vector Machines \n",
    "\n",
    "The models are imported from the sklearn libraries. The data is scaled using the preprocessing sklearn library, StandardScaler and a 7-fold cross validation is done for each model using the sklearn in built method cross_validate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plot\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Area</th>\n",
       "      <th>MajorAxisLength</th>\n",
       "      <th>MinorAxisLength</th>\n",
       "      <th>Eccentricity</th>\n",
       "      <th>ConvexArea</th>\n",
       "      <th>EquivDiameter</th>\n",
       "      <th>Extent</th>\n",
       "      <th>Perimeter</th>\n",
       "      <th>Roundness</th>\n",
       "      <th>AspectRation</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4537</td>\n",
       "      <td>92.229317</td>\n",
       "      <td>64.012769</td>\n",
       "      <td>0.719916</td>\n",
       "      <td>4677</td>\n",
       "      <td>76.004525</td>\n",
       "      <td>0.657536</td>\n",
       "      <td>273.085</td>\n",
       "      <td>0.764510</td>\n",
       "      <td>1.440796</td>\n",
       "      <td>jasmine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2872</td>\n",
       "      <td>74.691881</td>\n",
       "      <td>51.400454</td>\n",
       "      <td>0.725553</td>\n",
       "      <td>3015</td>\n",
       "      <td>60.471018</td>\n",
       "      <td>0.713009</td>\n",
       "      <td>208.317</td>\n",
       "      <td>0.831658</td>\n",
       "      <td>1.453137</td>\n",
       "      <td>jasmine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3048</td>\n",
       "      <td>76.293164</td>\n",
       "      <td>52.043491</td>\n",
       "      <td>0.731211</td>\n",
       "      <td>3132</td>\n",
       "      <td>62.296341</td>\n",
       "      <td>0.759153</td>\n",
       "      <td>210.012</td>\n",
       "      <td>0.868434</td>\n",
       "      <td>1.465950</td>\n",
       "      <td>jasmine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3073</td>\n",
       "      <td>77.033628</td>\n",
       "      <td>51.928487</td>\n",
       "      <td>0.738639</td>\n",
       "      <td>3157</td>\n",
       "      <td>62.551300</td>\n",
       "      <td>0.783529</td>\n",
       "      <td>210.657</td>\n",
       "      <td>0.870203</td>\n",
       "      <td>1.483456</td>\n",
       "      <td>jasmine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3693</td>\n",
       "      <td>85.124785</td>\n",
       "      <td>56.374021</td>\n",
       "      <td>0.749282</td>\n",
       "      <td>3802</td>\n",
       "      <td>68.571668</td>\n",
       "      <td>0.769375</td>\n",
       "      <td>230.332</td>\n",
       "      <td>0.874743</td>\n",
       "      <td>1.510000</td>\n",
       "      <td>jasmine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18180</th>\n",
       "      <td>18181</td>\n",
       "      <td>5853</td>\n",
       "      <td>148.624571</td>\n",
       "      <td>51.029281</td>\n",
       "      <td>0.939210</td>\n",
       "      <td>6008</td>\n",
       "      <td>86.326537</td>\n",
       "      <td>0.498594</td>\n",
       "      <td>332.960</td>\n",
       "      <td>0.663444</td>\n",
       "      <td>2.912535</td>\n",
       "      <td>Gonen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18181</th>\n",
       "      <td>18182</td>\n",
       "      <td>7585</td>\n",
       "      <td>169.593996</td>\n",
       "      <td>58.141659</td>\n",
       "      <td>0.939398</td>\n",
       "      <td>7806</td>\n",
       "      <td>98.272692</td>\n",
       "      <td>0.647461</td>\n",
       "      <td>385.506</td>\n",
       "      <td>0.641362</td>\n",
       "      <td>2.916910</td>\n",
       "      <td>Gonen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18182</th>\n",
       "      <td>18183</td>\n",
       "      <td>6365</td>\n",
       "      <td>154.777085</td>\n",
       "      <td>52.908085</td>\n",
       "      <td>0.939760</td>\n",
       "      <td>6531</td>\n",
       "      <td>90.023162</td>\n",
       "      <td>0.561287</td>\n",
       "      <td>342.253</td>\n",
       "      <td>0.682832</td>\n",
       "      <td>2.925396</td>\n",
       "      <td>Gonen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18183</th>\n",
       "      <td>18184</td>\n",
       "      <td>5960</td>\n",
       "      <td>151.397924</td>\n",
       "      <td>51.474600</td>\n",
       "      <td>0.940427</td>\n",
       "      <td>6189</td>\n",
       "      <td>87.112041</td>\n",
       "      <td>0.492399</td>\n",
       "      <td>343.371</td>\n",
       "      <td>0.635227</td>\n",
       "      <td>2.941216</td>\n",
       "      <td>Gonen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18184</th>\n",
       "      <td>18185</td>\n",
       "      <td>6134</td>\n",
       "      <td>153.081981</td>\n",
       "      <td>51.590606</td>\n",
       "      <td>0.941500</td>\n",
       "      <td>6283</td>\n",
       "      <td>88.374495</td>\n",
       "      <td>0.489975</td>\n",
       "      <td>338.613</td>\n",
       "      <td>0.672274</td>\n",
       "      <td>2.967245</td>\n",
       "      <td>Gonen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18185 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  Area  MajorAxisLength  MinorAxisLength  Eccentricity  \\\n",
       "0          1  4537        92.229317        64.012769      0.719916   \n",
       "1          2  2872        74.691881        51.400454      0.725553   \n",
       "2          3  3048        76.293164        52.043491      0.731211   \n",
       "3          4  3073        77.033628        51.928487      0.738639   \n",
       "4          5  3693        85.124785        56.374021      0.749282   \n",
       "...      ...   ...              ...              ...           ...   \n",
       "18180  18181  5853       148.624571        51.029281      0.939210   \n",
       "18181  18182  7585       169.593996        58.141659      0.939398   \n",
       "18182  18183  6365       154.777085        52.908085      0.939760   \n",
       "18183  18184  5960       151.397924        51.474600      0.940427   \n",
       "18184  18185  6134       153.081981        51.590606      0.941500   \n",
       "\n",
       "       ConvexArea  EquivDiameter    Extent  Perimeter  Roundness  \\\n",
       "0            4677      76.004525  0.657536    273.085   0.764510   \n",
       "1            3015      60.471018  0.713009    208.317   0.831658   \n",
       "2            3132      62.296341  0.759153    210.012   0.868434   \n",
       "3            3157      62.551300  0.783529    210.657   0.870203   \n",
       "4            3802      68.571668  0.769375    230.332   0.874743   \n",
       "...           ...            ...       ...        ...        ...   \n",
       "18180        6008      86.326537  0.498594    332.960   0.663444   \n",
       "18181        7806      98.272692  0.647461    385.506   0.641362   \n",
       "18182        6531      90.023162  0.561287    342.253   0.682832   \n",
       "18183        6189      87.112041  0.492399    343.371   0.635227   \n",
       "18184        6283      88.374495  0.489975    338.613   0.672274   \n",
       "\n",
       "       AspectRation    Class  \n",
       "0          1.440796  jasmine  \n",
       "1          1.453137  jasmine  \n",
       "2          1.465950  jasmine  \n",
       "3          1.483456  jasmine  \n",
       "4          1.510000  jasmine  \n",
       "...             ...      ...  \n",
       "18180      2.912535    Gonen  \n",
       "18181      2.916910    Gonen  \n",
       "18182      2.925396    Gonen  \n",
       "18183      2.941216    Gonen  \n",
       "18184      2.967245    Gonen  \n",
       "\n",
       "[18185 rows x 12 columns]"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('dataset_comb.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "jasmine    9985\n",
       "Gonen      8200\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18185, 12)"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Area</th>\n",
       "      <th>MajorAxisLength</th>\n",
       "      <th>MinorAxisLength</th>\n",
       "      <th>Eccentricity</th>\n",
       "      <th>ConvexArea</th>\n",
       "      <th>EquivDiameter</th>\n",
       "      <th>Extent</th>\n",
       "      <th>Perimeter</th>\n",
       "      <th>Roundness</th>\n",
       "      <th>AspectRation</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4537</td>\n",
       "      <td>92.229317</td>\n",
       "      <td>64.012769</td>\n",
       "      <td>0.719916</td>\n",
       "      <td>4677</td>\n",
       "      <td>76.004525</td>\n",
       "      <td>0.657536</td>\n",
       "      <td>273.085</td>\n",
       "      <td>0.764510</td>\n",
       "      <td>1.440796</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2872</td>\n",
       "      <td>74.691881</td>\n",
       "      <td>51.400454</td>\n",
       "      <td>0.725553</td>\n",
       "      <td>3015</td>\n",
       "      <td>60.471018</td>\n",
       "      <td>0.713009</td>\n",
       "      <td>208.317</td>\n",
       "      <td>0.831658</td>\n",
       "      <td>1.453137</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3048</td>\n",
       "      <td>76.293164</td>\n",
       "      <td>52.043491</td>\n",
       "      <td>0.731211</td>\n",
       "      <td>3132</td>\n",
       "      <td>62.296341</td>\n",
       "      <td>0.759153</td>\n",
       "      <td>210.012</td>\n",
       "      <td>0.868434</td>\n",
       "      <td>1.465950</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3073</td>\n",
       "      <td>77.033628</td>\n",
       "      <td>51.928487</td>\n",
       "      <td>0.738639</td>\n",
       "      <td>3157</td>\n",
       "      <td>62.551300</td>\n",
       "      <td>0.783529</td>\n",
       "      <td>210.657</td>\n",
       "      <td>0.870203</td>\n",
       "      <td>1.483456</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3693</td>\n",
       "      <td>85.124785</td>\n",
       "      <td>56.374021</td>\n",
       "      <td>0.749282</td>\n",
       "      <td>3802</td>\n",
       "      <td>68.571668</td>\n",
       "      <td>0.769375</td>\n",
       "      <td>230.332</td>\n",
       "      <td>0.874743</td>\n",
       "      <td>1.510000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  Area  MajorAxisLength  MinorAxisLength  Eccentricity  ConvexArea  \\\n",
       "0   1  4537        92.229317        64.012769      0.719916        4677   \n",
       "1   2  2872        74.691881        51.400454      0.725553        3015   \n",
       "2   3  3048        76.293164        52.043491      0.731211        3132   \n",
       "3   4  3073        77.033628        51.928487      0.738639        3157   \n",
       "4   5  3693        85.124785        56.374021      0.749282        3802   \n",
       "\n",
       "   EquivDiameter    Extent  Perimeter  Roundness  AspectRation  Class  \n",
       "0      76.004525  0.657536    273.085   0.764510      1.440796      1  \n",
       "1      60.471018  0.713009    208.317   0.831658      1.453137      1  \n",
       "2      62.296341  0.759153    210.012   0.868434      1.465950      1  \n",
       "3      62.551300  0.783529    210.657   0.870203      1.483456      1  \n",
       "4      68.571668  0.769375    230.332   0.874743      1.510000      1  "
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "df['Class'] = le.fit_transform(df['Class'])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.values[:,1:-1]\n",
    "Y = df.values[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "average= {}\n",
    "maxm= {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fisher Linear Discriminant "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Fisher Linear Discriminant Analysis is a classification technique that identifies the linear combination of features that characterizes or separates two or more classes. \n",
    "The model fits a Gaussian density to each class, assuming that all classes share the same covariance matrix.\n",
    "\n",
    "We import the sklearn LinearDiscrminantAnalysis model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold  1\n",
      "Testing Accuracy =  0.8598922247882987  Training Accuracy =  0.9910181561557708\n",
      "Fold  2\n",
      "Testing Accuracy =  0.9992301770592764  Training Accuracy =  0.9861422980689035\n",
      "Fold  3\n",
      "Testing Accuracy =  0.9996150885296382  Training Accuracy =  0.9851799576570219\n",
      "Fold  4\n",
      "Testing Accuracy =  0.9984603541185527  Training Accuracy =  0.9847950214922692\n",
      "Fold  5\n",
      "Testing Accuracy =  0.9980754426481909  Training Accuracy =  0.9840893051902226\n",
      "Fold  6\n",
      "Testing Accuracy =  0.993841416474211  Training Accuracy =  0.9841534612176814\n",
      "Fold  7\n",
      "Testing Accuracy =  0.9068155564112438  Training Accuracy =  0.9967282525019245\n",
      "\n",
      "Average test accuracy=  0.9651328942899161 \n",
      "\n",
      "Precision over fold  1  =  1.0\n",
      "Precision over fold  2  =  0.9992992291520673\n",
      "Precision over fold  3  =  0.9992997198879552\n",
      "Precision over fold  4  =  0.9972027972027973\n",
      "Precision over fold  5  =  0.9965059399021663\n",
      "Precision over fold  6  =  0.9889042995839112\n",
      "Precision over fold  7  =  0.854916067146283\n",
      "\n",
      "\n",
      "Recall over fold  1  =  0.7449194113524877\n",
      "Recall over fold  2  =  0.9992992291520673\n",
      "Recall over fold  3  =  1.0\n",
      "Recall over fold  4  =  1.0\n",
      "Recall over fold  5  =  1.0\n",
      "Recall over fold  6  =  1.0\n",
      "Recall over fold  7  =  1.0\n"
     ]
    }
   ],
   "source": [
    "#pipe = Pipeline([('scaler', MinMaxScaler()), ('fda', LinearDiscriminantAnalysis())]) #scaling not required\n",
    "fda_scores = cross_validate(LinearDiscriminantAnalysis(),X,Y,cv=7,return_train_score=True)\n",
    "for i,(score, scoret) in enumerate(zip(fda_scores['test_score'],fda_scores['train_score'])):\n",
    "    print(\"Fold \",i+1)\n",
    "    print(\"Testing Accuracy = \",score,\" Training Accuracy = \",scoret)\n",
    "\n",
    "average['Fisher Discriminant']= np.average(fda_scores['test_score'])\n",
    "maxm['Fisher Discriminant']=np.amax(fda_scores['test_score'])\n",
    "print(\"\\nAverage test accuracy= \",average['Fisher Discriminant'],\"\\n\")\n",
    "\n",
    "fda_prec = cross_validate(LinearDiscriminantAnalysis(),X,Y,cv=7,scoring='precision')\n",
    "for i,score in enumerate(fda_prec['test_score']):\n",
    "    print(\"Precision over fold \",i+1,\" = \",score)\n",
    "print(\"\\n\")\n",
    "fda_rec = cross_validate(LinearDiscriminantAnalysis(),X,Y,cv=7,scoring='recall')\n",
    "for i,score in enumerate(fda_rec['test_score']):\n",
    "    print(\"Recall over fold \",i+1,\" = \",score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Perceptron "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Perceptron is a linear classification algorithm that makes its predictions based on a linear predictor function combining a set of weights with the feature vector. It uses the Gradient Descent Algorithm to update the weights based on misclassified points on each iteration.\n",
    "\n",
    "We import the sklearn Perceptron model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold  1\n",
      "Testing Accuracy =  0.5969976905311778  Training Accuracy =  0.9974337589016488\n",
      "Fold  2\n",
      "Testing Accuracy =  0.9992301770592764  Training Accuracy =  0.9769679861422981\n",
      "Fold  3\n",
      "Testing Accuracy =  0.9846035411855273  Training Accuracy =  0.9722845961378072\n",
      "Fold  4\n",
      "Testing Accuracy =  1.0  Training Accuracy =  0.9867197023160326\n",
      "Fold  5\n",
      "Testing Accuracy =  1.0  Training Accuracy =  0.9831911208057997\n",
      "Fold  6\n",
      "Testing Accuracy =  0.99153194765204  Training Accuracy =  0.9803040995701546\n",
      "Fold  7\n",
      "Testing Accuracy =  0.9306892568348094  Training Accuracy =  0.9961508852963818\n",
      "\n",
      "Average test accuracy=  0.9290075161804044 \n",
      "\n",
      "Precision over fold  1  =  1.0\n",
      "Precision over fold  2  =  1.0\n",
      "Precision over fold  3  =  0.9894142554693014\n",
      "Precision over fold  4  =  1.0\n",
      "Precision over fold  5  =  1.0\n",
      "Precision over fold  6  =  0.9848066298342542\n",
      "Precision over fold  7  =  0.887920298879203\n",
      "\n",
      "\n",
      "Recall over fold  1  =  0.2662929222144359\n",
      "Recall over fold  2  =  0.9985984583041345\n",
      "Recall over fold  3  =  0.9824807288016818\n",
      "Recall over fold  4  =  1.0\n",
      "Recall over fold  5  =  1.0\n",
      "Recall over fold  6  =  1.0\n",
      "Recall over fold  7  =  1.0\n"
     ]
    }
   ],
   "source": [
    "pipeLP = Pipeline([('scaler', StandardScaler()), ('per', Perceptron())])  #or use MinMaxScaler\n",
    "per_scores = cross_validate(pipeLP,X,Y,cv=7,return_train_score=True)\n",
    "for i,(score, scoret) in enumerate(zip(per_scores['test_score'],per_scores['train_score'])):\n",
    "    print(\"Fold \",i+1)\n",
    "    print(\"Testing Accuracy = \",score,\" Training Accuracy = \",scoret)\n",
    "\n",
    "average['Perceptron']=np.average(per_scores['test_score'])\n",
    "maxm['Perceptron']=np.amax(per_scores['test_score'])\n",
    "print(\"\\nAverage test accuracy= \",average['Perceptron'],\"\\n\")\n",
    "\n",
    "per_prec = cross_validate(pipeLP,X,Y,cv=7,scoring='precision')\n",
    "for i,score in enumerate(per_prec['test_score']):\n",
    "    print(\"Precision over fold \",i+1,\" = \",score)\n",
    "print(\"\\n\")\n",
    "per_rec = cross_validate(pipeLP,X,Y,cv=7,scoring='recall')\n",
    "for i,score in enumerate(per_rec['test_score']):\n",
    "    print(\"Recall over fold \",i+1,\" = \",score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes algorithms are a set of supervised statistical classification machine learning algorithms based on the Bayes probability theorem.\n",
    "\n",
    "Bayes theorem states that:\n",
    "\n",
    "$$P(A|B) = \\frac{P(B/A) * P(A)}{P(B)}$$$$P(A|B) = \\frac{P(B/A) * P(A)}{P(B/A) * P(A) + P(C/A) * P(A)}$$\n",
    "An important assumption made by Bayes theorem is that the value of a particular feature is independent from the value of any other feature for a given the class.\n",
    "\n",
    "We import the sklearn GaussianNB model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold  1\n",
      "Testing Accuracy =  0.8852963818321786  Training Accuracy =  0.9919163405401937\n",
      "Fold  2\n",
      "Testing Accuracy =  0.9969207082371054  Training Accuracy =  0.9819080002566241\n",
      "Fold  3\n",
      "Testing Accuracy =  0.9953810623556582  Training Accuracy =  0.9818438442291654\n",
      "Fold  4\n",
      "Testing Accuracy =  0.9957659738260201  Training Accuracy =  0.9813947520369539\n",
      "Fold  5\n",
      "Testing Accuracy =  0.9907621247113164  Training Accuracy =  0.9815230640918714\n",
      "Fold  6\n",
      "Testing Accuracy =  0.9872979214780601  Training Accuracy =  0.9814589080644126\n",
      "Fold  7\n",
      "Testing Accuracy =  0.9102810935695033  Training Accuracy =  0.9926225301513986\n",
      "\n",
      "Average test accuracy=  0.9659578951442631 \n",
      "\n",
      "Precision over fold  1  =  1.0\n",
      "Precision over fold  2  =  0.9944250871080139\n",
      "Precision over fold  3  =  0.9916608756080612\n",
      "Precision over fold  4  =  0.9923451635351427\n",
      "Precision over fold  5  =  0.983448275862069\n",
      "Precision over fold  6  =  0.9773817683344757\n",
      "Precision over fold  7  =  0.8595539481615431\n",
      "\n",
      "\n",
      "Recall over fold  1  =  0.7911702873160477\n",
      "Recall over fold  2  =  1.0\n",
      "Recall over fold  3  =  1.0\n",
      "Recall over fold  4  =  1.0\n",
      "Recall over fold  5  =  1.0\n",
      "Recall over fold  6  =  1.0\n",
      "Recall over fold  7  =  1.0\n"
     ]
    }
   ],
   "source": [
    "pipeNB = Pipeline([('scaler', StandardScaler()), ('nb', GaussianNB())]) #scaling not required i think\n",
    "nb_scores = cross_validate(pipeNB,X,Y,cv=7,return_train_score=True)\n",
    "for i,(score, scoret) in enumerate(zip(nb_scores['test_score'],nb_scores['train_score'])):\n",
    "    print(\"Fold \",i+1)\n",
    "    print(\"Testing Accuracy = \",score,\" Training Accuracy = \",scoret)\n",
    "\n",
    "average['Naive Bayes']=np.average(nb_scores['test_score'])\n",
    "maxm['Naive Bayes']=np.amax(nb_scores['test_score'])\n",
    "print(\"\\nAverage test accuracy= \",average['Naive Bayes'],\"\\n\")\n",
    "\n",
    "nb_prec = cross_validate(pipeNB,X,Y,cv=7,scoring='precision')\n",
    "for i,score in enumerate(nb_prec['test_score']):\n",
    "    print(\"Precision over fold \",i+1,\" = \",score)\n",
    "print(\"\\n\")\n",
    "nb_rec = cross_validate(pipeNB,X,Y,cv=7,scoring='recall')\n",
    "for i,score in enumerate(nb_rec['test_score']):\n",
    "    print(\"Recall over fold \",i+1,\" = \",score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression is a machine learning algorithm for classification. In this algorithm, the probabilities describing the possible outcomes of a single trial are modelled using a logistic function.\n",
    "\n",
    "We import the sklearn LogisticRegression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold  1\n",
      "Testing Accuracy =  0.7063125481139338  Training Accuracy =  0.9969205106819786\n",
      "Fold  2\n",
      "Testing Accuracy =  0.9988452655889145  Training Accuracy =  0.9871046384807852\n",
      "Fold  3\n",
      "Testing Accuracy =  1.0  Training Accuracy =  0.9872971065631616\n",
      "Fold  4\n",
      "Testing Accuracy =  1.0  Training Accuracy =  0.9874254186180792\n",
      "Fold  5\n",
      "Testing Accuracy =  0.9996150885296382  Training Accuracy =  0.9875537306729967\n",
      "Fold  6\n",
      "Testing Accuracy =  0.9965357967667436  Training Accuracy =  0.9878745108102907\n",
      "Fold  7\n",
      "Testing Accuracy =  0.9287639584135541  Training Accuracy =  0.9960225814729279\n",
      "\n",
      "Average test accuracy=  0.9471532367732548 \n",
      "\n",
      "Precision over fold  1  =  1.0\n",
      "Precision over fold  2  =  0.9992987377279102\n",
      "Precision over fold  3  =  1.0\n",
      "Precision over fold  4  =  1.0\n",
      "Precision over fold  5  =  0.9992992291520673\n",
      "Precision over fold  6  =  0.9937282229965156\n",
      "Precision over fold  7  =  0.8851644941030415\n",
      "\n",
      "\n",
      "Recall over fold  1  =  0.4653118430273301\n",
      "Recall over fold  2  =  0.9985984583041345\n",
      "Recall over fold  3  =  1.0\n",
      "Recall over fold  4  =  1.0\n",
      "Recall over fold  5  =  1.0\n",
      "Recall over fold  6  =  1.0\n",
      "Recall over fold  7  =  1.0\n"
     ]
    }
   ],
   "source": [
    "pipeLR = Pipeline([('scaler', StandardScaler()), ('lr', LogisticRegression(solver='liblinear'))])\n",
    "lr_scores = cross_validate(pipeLR,X,Y,cv=7,return_train_score=True)\n",
    "for i,(score, scoret) in enumerate(zip(lr_scores['test_score'],lr_scores['train_score'])):\n",
    "    print(\"Fold \",i+1)\n",
    "    print(\"Testing Accuracy = \",score,\" Training Accuracy = \",scoret)\n",
    "\n",
    "average['Logistic Regression']=np.average(lr_scores['test_score'])\n",
    "maxm['Logistic Regression']=np.amax(lr_scores['test_score'])\n",
    "print(\"\\nAverage test accuracy= \",average['Logistic Regression'],\"\\n\")\n",
    "\n",
    "lr_prec = cross_validate(pipeLR,X,Y,cv=7,scoring='precision')\n",
    "for i,score in enumerate(lr_prec['test_score']):\n",
    "    print(\"Precision over fold \",i+1,\" = \",score)\n",
    "print(\"\\n\")\n",
    "lr_rec = cross_validate(pipeLR,X,Y,cv=7,scoring='recall')\n",
    "for i,score in enumerate(lr_rec['test_score']):\n",
    "    print(\"Recall over fold \",i+1,\" = \",score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Artificial Neural Network "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Artificial neural network is a machine learning technique used for classification problems. ANN is a set of connected input output network in which weight is associated with each connection. It consists of one input layer, one or more intermediate layer and one output layer.\n",
    "A Multi Layer Perceptron is a supervised learning technique with a feed forward artificial neural network through back-propagation that can classify non-linearly separable data.\n",
    "\n",
    "We import the sklearn MLPClassifier model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold  1\n",
      "Testing Accuracy =  0.6200923787528868  Training Accuracy =  0.9976903830114839\n",
      "Fold  2\n",
      "Testing Accuracy =  0.9984603541185527  Training Accuracy =  0.9890293193045486\n",
      "Fold  3\n",
      "Testing Accuracy =  0.9992301770592764  Training Accuracy =  0.9887085391672548\n",
      "Fold  4\n",
      "Testing Accuracy =  0.9988452655889145  Training Accuracy =  0.9891576313594662\n",
      "Fold  5\n",
      "Testing Accuracy =  0.9992301770592764  Training Accuracy =  0.989221787386925\n",
      "Fold  6\n",
      "Testing Accuracy =  0.9961508852963818  Training Accuracy =  0.9892859434143838\n",
      "Fold  7\n",
      "Testing Accuracy =  0.8656141701963804  Training Accuracy =  0.9983320502950987\n",
      "\n",
      "Average test accuracy=  0.925374772581667 \n",
      "\n",
      "Precision over fold  1  =  1.0\n",
      "Precision over fold  2  =  0.9979020979020979\n",
      "Precision over fold  3  =  0.9992997198879552\n",
      "Precision over fold  4  =  0.9992992291520673\n",
      "Precision over fold  5  =  0.9985994397759104\n",
      "Precision over fold  6  =  0.9958100558659218\n",
      "Precision over fold  7  =  0.8111490329920364\n",
      "\n",
      "\n",
      "Recall over fold  1  =  0.3391730903994394\n",
      "Recall over fold  2  =  0.9978976874562018\n",
      "Recall over fold  3  =  1.0\n",
      "Recall over fold  4  =  1.0\n",
      "Recall over fold  5  =  1.0\n",
      "Recall over fold  6  =  1.0\n",
      "Recall over fold  7  =  1.0\n"
     ]
    }
   ],
   "source": [
    "pipeNN = Pipeline([('scaler', StandardScaler()), ('ann', MLPClassifier())])\n",
    "nn_scores = cross_validate(pipeNN,X,Y,cv=7,return_train_score=True)\n",
    "for i,(score, scoret) in enumerate(zip(nn_scores['test_score'],nn_scores['train_score'])):\n",
    "    print(\"Fold \",i+1)\n",
    "    print(\"Testing Accuracy = \",score,\" Training Accuracy = \",scoret)\n",
    "\n",
    "average['Neural Network']=np.average(nn_scores['test_score'])\n",
    "maxm['Neural Network']=np.amax(nn_scores['test_score'])\n",
    "print(\"\\nAverage test accuracy= \",np.average(nn_scores['test_score']),\"\\n\")\n",
    "\n",
    "nn_prec = cross_validate(pipeNN,X,Y,cv=7,scoring='precision')\n",
    "for i,score in enumerate(nn_prec['test_score']):\n",
    "    print(\"Precision over fold \",i+1,\" = \",score)\n",
    "print(\"\\n\")\n",
    "nn_rec = cross_validate(pipeNN,X,Y,cv=7,scoring='recall')\n",
    "for i,score in enumerate(nn_rec['test_score']):\n",
    "    print(\"Recall over fold \",i+1,\" = \",score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support vector machines (SVMs) are a set of supervised learning methods used for classification. They are efective forigh dimensional spaces and cases where number of dimensions is greater than the number of samples.\n",
    "\n",
    "We import the sklearn svm.SVC model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold  1\n",
      "Testing Accuracy =  0.7802155504234026  Training Accuracy =  0.996792198627061\n",
      "Fold  2\n",
      "Testing Accuracy =  1.0  Training Accuracy =  0.9889010072496311\n",
      "Fold  3\n",
      "Testing Accuracy =  0.9996150885296382  Training Accuracy =  0.9889010072496311\n",
      "Fold  4\n",
      "Testing Accuracy =  0.9992301770592764  Training Accuracy =  0.989221787386925\n",
      "Fold  5\n",
      "Testing Accuracy =  0.9996150885296382  Training Accuracy =  0.9890934753320074\n",
      "Fold  6\n",
      "Testing Accuracy =  0.9976905311778291  Training Accuracy =  0.9891576313594662\n",
      "Fold  7\n",
      "Testing Accuracy =  0.8860223334616866  Training Accuracy =  0.9974980754426482\n",
      "\n",
      "Average test accuracy=  0.9517698241687816 \n",
      "\n",
      "Precision over fold  1  =  0.9314516129032258\n",
      "Precision over fold  2  =  1.0\n",
      "Precision over fold  3  =  0.9992997198879552\n",
      "Precision over fold  4  =  0.9985994397759104\n",
      "Precision over fold  5  =  0.9992992291520673\n",
      "Precision over fold  6  =  0.9958100558659218\n",
      "Precision over fold  7  =  0.8281068524970964\n",
      "\n",
      "\n",
      "Recall over fold  1  =  0.6475122634898388\n",
      "Recall over fold  2  =  1.0\n",
      "Recall over fold  3  =  1.0\n",
      "Recall over fold  4  =  1.0\n",
      "Recall over fold  5  =  1.0\n",
      "Recall over fold  6  =  1.0\n",
      "Recall over fold  7  =  1.0\n"
     ]
    }
   ],
   "source": [
    "pipesvm = Pipeline([('scaler', StandardScaler()), ('svm', SVC(kernel='rbf'))])  #kernel can linear or rbf or...  rbf gives highest acc\n",
    "svm_scores = cross_validate(pipesvm,X,Y,cv=7,return_train_score=True)\n",
    "for i,(score, scoret) in enumerate(zip(svm_scores['test_score'],svm_scores['train_score'])):\n",
    "    print(\"Fold \",i+1)\n",
    "    print(\"Testing Accuracy = \",score,\" Training Accuracy = \",scoret)\n",
    "    \n",
    "average['SVM']=np.average(svm_scores['test_score'])\n",
    "maxm['SVM']=np.amax(svm_scores['test_score'])\n",
    "print(\"\\nAverage test accuracy= \",average['SVM'],\"\\n\")\n",
    "\n",
    "svm_prec = cross_validate(pipesvm,X,Y,cv=7,scoring='precision')\n",
    "for i,score in enumerate(svm_prec['test_score']):\n",
    "    print(\"Precision over fold \",i+1,\" = \",score)\n",
    "print(\"\\n\")\n",
    "svm_rec = cross_validate(pipesvm,X,Y,cv=7,scoring='recall')\n",
    "for i,score in enumerate(svm_rec['test_score']):\n",
    "    print(\"Recall over fold \",i+1,\" = \",score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boxplots of Testing Accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plot.subplots()\n",
    "ax.boxplot([fda_scores['test_score'],per_scores['test_score'],nb_scores['test_score'],lr_scores['test_score'],nn_scores['test_score'],svm_scores['test_score']])\n",
    "ax.set_xticklabels(['Fisher','Perceptron','NB','Log Regr','ANN','SVM'])\n",
    "#plot.ylim([0.92,1.01])\n",
    "plot.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boxplots of Training Accuracies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plot.subplots()\n",
    "ax.boxplot([fda_scores['train_score'],per_scores['train_score'],nb_scores['train_score'],lr_scores['train_score'],nn_scores['train_score'],svm_scores['train_score']])\n",
    "ax.set_xticklabels(['Fisher','Perceptron','NB','Log Regr','ANN','SVM'])\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The average test accuracy over the 7 folds for each classification model shows Naive Bayes having the highest accuracy, and ANN having the least. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Average Testing Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fisher Discriminant</td>\n",
       "      <td>0.965133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>0.929008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.965958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.947153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Neural Network</td>\n",
       "      <td>0.925375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.951770</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Average Testing Accuracy\n",
       "0  Fisher Discriminant                  0.965133\n",
       "1           Perceptron                  0.929008\n",
       "2          Naive Bayes                  0.965958\n",
       "3  Logistic Regression                  0.947153\n",
       "4       Neural Network                  0.925375\n",
       "5                  SVM                  0.951770"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.DataFrame(list(average.items()),columns = ['Model','Average Testing Accuracy']) \n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The maximum test accuracy obtained in a fold for each classification model shows Perceptron, Logistic Regression and SVM having a 100% accuracy, and Naive Bayes having the least."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Maximum Testing Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fisher Discriminant</td>\n",
       "      <td>0.999615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.996921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Neural Network</td>\n",
       "      <td>0.999230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVM</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Maximum Testing Accuracy\n",
       "0  Fisher Discriminant                  0.999615\n",
       "1           Perceptron                  1.000000\n",
       "2          Naive Bayes                  0.996921\n",
       "3  Logistic Regression                  1.000000\n",
       "4       Neural Network                  0.999230\n",
       "5                  SVM                  1.000000"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.DataFrame(list(maxm.items()),columns = ['Model','Maximum Testing Accuracy']) \n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The boxplots of the training accuracies show that ANN and SVM perform the best while training the datasets, while NB performs the worst.\n",
    "- Linear Perceptron has the highest variance as shown by its boxplot. This could be due to the fact it makes random predictions of the weights while training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The boxplots of the testing accuracies show a near 100% median accuracy for all models. Median Accuracies for ANN, SVM and Logistic Regression are higher than the others'. \n",
    "- However due to presence of outliers from the first fold in all models the mean accuracy for NB turns out to be the highest.\n",
    "- The high accuracy of Fisher LDA could indicate that the the data is in fact linearly seperable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
