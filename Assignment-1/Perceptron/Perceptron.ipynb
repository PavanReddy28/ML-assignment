{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The underlying formula for classification of the perceptron algorithm is given by:  \n",
    "$y = f(w^{T}\\phi(x))$\n",
    "  \n",
    "where $f(a)$ is given by \n",
    "  \n",
    "$f(a) =\n",
    "   \\left\\{\n",
    "\\begin{array}{ll}\n",
    "      +1 & a\\geq 0 \\\\\n",
    "      -1 & a < 0 \\\\\n",
    "\\end{array} \n",
    "\\right.$\n",
    "\n",
    "- The vector $w$ is obtained by training on a dataset for a some iterations using gradient descent.\n",
    "  \n",
    "- The perceptron criterion is given by:  \n",
    "  \n",
    "$E_{p}(w) = \\sum_{n \\in M}w^{T}\\phi_{n}t_{n}$\n",
    "\n",
    "- The update of w for every misclassified point is then given by: \n",
    "  \n",
    "$w^{\\tau + 1} = w^{\\tau} + \\eta\\phi_{n}t_{n}$\n",
    "  \n",
    "where $\\eta$ is the learning rate\n",
    "\n",
    "### Implementation\n",
    "\n",
    "- The algorithm uses NumPy,pandas and matplotlib as dependencies\n",
    "- The training and testing data are vectorized using NumPy to generate predictions without explicit for loops\n",
    "- The datasets are shuffled and split into 70:30 training and testing splits respectively\n",
    "- Different learning rates and iterations have been chosen for the given datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(data,split,randomize=True):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "        data: numpy array of the dataset\n",
    "        split: percentage of the samples required for the training data\n",
    "        randomize: boolean representing whether you want to randomize the dataset\n",
    "    Returns:\n",
    "        train_X: numpy array containing training data\n",
    "        train_y: numpy array containing the training labels\n",
    "        test_X: numpy array containing testing data\n",
    "        test_y: numpy array containing the testing labels\n",
    "    \"\"\"\n",
    "    \n",
    "    split_index = int(split*len(data))\n",
    "    \n",
    "    # randomly shuffles rows of the dataset\n",
    "    if randomize == True:\n",
    "        np.random.shuffle(data)\n",
    "    \n",
    "    \n",
    "    X = data[:,:-1]\n",
    "    y = data[:,-1]\n",
    "    \n",
    "    train_X = X[:split_index]\n",
    "    train_y = y[:split_index]\n",
    "    \n",
    "    test_X = X[split_index:]\n",
    "    test_y = y[split_index:]\n",
    "    \n",
    "    return train_X,train_y,test_X,test_y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "    \n",
    "    def predict(self,X):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "            X: numpy array containing examples from which predictions needs to be made\n",
    "        Returns:\n",
    "            predictions: numpy array of the predictions\n",
    "        \"\"\"\n",
    "\n",
    "        activations = X.dot(self.weights[1:])\n",
    "        activations += self.weights[0]\n",
    "\n",
    "        predictions  = np.heaviside(activations,0)\n",
    "\n",
    "\n",
    "        return predictions\n",
    "    \n",
    "    def fit(self,train_X,train_y,iterations = 100,learning_rate = 0.0001):\n",
    "        \"\"\"\n",
    "        Updates the weights using gradient descent using a fixed number of iterations and a learning rate\n",
    "        Parameters:\n",
    "            train_X: numpy array containing training data\n",
    "            train_y: numpy array containing the training labels\n",
    "            iterations: number of iterations for gradient descent\n",
    "            learning_rate: learning rate for gradient descent\n",
    "        \"\"\"\n",
    "        \n",
    "        self.weights = np.random.normal(loc=0,scale=0.01,size=train_X.shape[1]+1)\n",
    "        \n",
    "        \n",
    "        for i in tqdm(range(iterations)):\n",
    "\n",
    "            predictions = self.predict(train_X)\n",
    "\n",
    "            loss = np.sum(-1*(train_X.dot(self.weights[1:])+self.weights[0])*(train_y-predictions))\n",
    "\n",
    "            for j,prediction in enumerate(predictions):\n",
    "                self.weights += learning_rate*(np.insert(train_X[j],0,1))*(train_y[j]-prediction)\n",
    "                \n",
    "                \n",
    "        print(\"Final loss = {:.2f}\".format(loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(train_X,train_y,test_X,test_y,perceptron):\n",
    "    \"\"\"\n",
    "    Evaluates the training and testing accuracy given a perceptron model\n",
    "    \n",
    "    Parameters:\n",
    "        train_X: numpy array containing training data\n",
    "        train_y: numpy array containing the training labels\n",
    "        test_X: numpy array containing testing data\n",
    "        test_y: numpy array containing the testing labels\n",
    "    \"\"\"\n",
    "    train_predictions = perceptron.predict(train_X)\n",
    "    test_predictions = perceptron.predict(test_X)\n",
    "\n",
    "    testing_accuracy = 100*np.sum((test_predictions == test_y))/len(test_y)\n",
    "    training_accuracy = 100*np.sum((train_predictions == train_y))/len(train_y)\n",
    "\n",
    "    print(\"Training accuracy = {:.2f}%\".format(training_accuracy))\n",
    "    print(\"Testing accuracy = {:.2f}%\".format(testing_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataset_LP_2.csv',header = None)\n",
    "df.columns = [\"feature 1\",\"feature 2\", \"feature 3\",\"label\"]\n",
    "\n",
    "# txt file can also be read with read csv because all the values are comma seperated\n",
    "# df_2 = pd.read_csv('dataset_LP_1.txt',header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature 1</th>\n",
       "      <th>feature 2</th>\n",
       "      <th>feature 3</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-6.672418</td>\n",
       "      <td>-1.206198</td>\n",
       "      <td>-1.081050</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.675598</td>\n",
       "      <td>0.614994</td>\n",
       "      <td>-0.971600</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-4.039058</td>\n",
       "      <td>0.335102</td>\n",
       "      <td>0.544618</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.793526</td>\n",
       "      <td>-0.235277</td>\n",
       "      <td>0.551771</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.820273</td>\n",
       "      <td>-0.274691</td>\n",
       "      <td>0.454743</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>-3.680139</td>\n",
       "      <td>0.966962</td>\n",
       "      <td>-0.904337</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>-4.063900</td>\n",
       "      <td>0.802611</td>\n",
       "      <td>1.023708</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>-0.814430</td>\n",
       "      <td>-0.693945</td>\n",
       "      <td>0.876776</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>-0.325122</td>\n",
       "      <td>-0.759024</td>\n",
       "      <td>1.299772</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>-1.503431</td>\n",
       "      <td>-0.269458</td>\n",
       "      <td>-1.124390</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     feature 1  feature 2  feature 3  label\n",
       "0    -6.672418  -1.206198  -1.081050      0\n",
       "1     1.675598   0.614994  -0.971600      0\n",
       "2    -4.039058   0.335102   0.544618      1\n",
       "3     0.793526  -0.235277   0.551771      1\n",
       "4     3.820273  -0.274691   0.454743      1\n",
       "..         ...        ...        ...    ...\n",
       "995  -3.680139   0.966962  -0.904337      0\n",
       "996  -4.063900   0.802611   1.023708      1\n",
       "997  -0.814430  -0.693945   0.876776      1\n",
       "998  -0.325122  -0.759024   1.299772      1\n",
       "999  -1.503431  -0.269458  -1.124390      0\n",
       "\n",
       "[1000 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df\n",
    "# Note: here the targets tn is either 0 or 1 unlike in class where it is -1 and 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "counts = df['label'].value_counts()\n",
    "plt.bar(['1','0'], counts)\n",
    "plt.xlabel('class')\n",
    "plt.ylabel('# samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = df.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now split the data into a 70%-30% split fot training and testing respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [00:06<00:00, 76.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final loss = 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_X,train_y,test_X,test_y = train_test_split(data,0.7)\n",
    "perceptron = Perceptron()\n",
    "perceptron.fit(train_X,train_y,learning_rate = 0.001,iterations=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy = 100.00%\n",
      "Testing accuracy = 100.00%\n"
     ]
    }
   ],
   "source": [
    "evaluate(train_X,train_y,test_X,test_y,perceptron)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset - 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will load the dataset into a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataset_LP_1.txt',header = None)\n",
    "df.columns = [\"feature 1\",\"feature 2\", \"feature 3\",\"feature 4\",\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature 1</th>\n",
       "      <th>feature 2</th>\n",
       "      <th>feature 3</th>\n",
       "      <th>feature 4</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.62160</td>\n",
       "      <td>8.66610</td>\n",
       "      <td>-2.8073</td>\n",
       "      <td>-0.44699</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.54590</td>\n",
       "      <td>8.16740</td>\n",
       "      <td>-2.4586</td>\n",
       "      <td>-1.46210</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.86600</td>\n",
       "      <td>-2.63830</td>\n",
       "      <td>1.9242</td>\n",
       "      <td>0.10645</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.45660</td>\n",
       "      <td>9.52280</td>\n",
       "      <td>-4.0112</td>\n",
       "      <td>-3.59440</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.32924</td>\n",
       "      <td>-4.45520</td>\n",
       "      <td>4.5718</td>\n",
       "      <td>-0.98880</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1367</th>\n",
       "      <td>0.40614</td>\n",
       "      <td>1.34920</td>\n",
       "      <td>-1.4501</td>\n",
       "      <td>-0.55949</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1368</th>\n",
       "      <td>-1.38870</td>\n",
       "      <td>-4.87730</td>\n",
       "      <td>6.4774</td>\n",
       "      <td>0.34179</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1369</th>\n",
       "      <td>-3.75030</td>\n",
       "      <td>-13.45860</td>\n",
       "      <td>17.5932</td>\n",
       "      <td>-2.77710</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1370</th>\n",
       "      <td>-3.56370</td>\n",
       "      <td>-8.38270</td>\n",
       "      <td>12.3930</td>\n",
       "      <td>-1.28230</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1371</th>\n",
       "      <td>-2.54190</td>\n",
       "      <td>-0.65804</td>\n",
       "      <td>2.6842</td>\n",
       "      <td>1.19520</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1372 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      feature 1  feature 2  feature 3  feature 4  label\n",
       "0       3.62160    8.66610    -2.8073   -0.44699      0\n",
       "1       4.54590    8.16740    -2.4586   -1.46210      0\n",
       "2       3.86600   -2.63830     1.9242    0.10645      0\n",
       "3       3.45660    9.52280    -4.0112   -3.59440      0\n",
       "4       0.32924   -4.45520     4.5718   -0.98880      0\n",
       "...         ...        ...        ...        ...    ...\n",
       "1367    0.40614    1.34920    -1.4501   -0.55949      1\n",
       "1368   -1.38870   -4.87730     6.4774    0.34179      1\n",
       "1369   -3.75030  -13.45860    17.5932   -2.77710      1\n",
       "1370   -3.56370   -8.38270    12.3930   -1.28230      1\n",
       "1371   -2.54190   -0.65804     2.6842    1.19520      1\n",
       "\n",
       "[1372 rows x 5 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The counts of each label is given below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "counts = df['label'].value_counts()\n",
    "plt.bar(['1','0'], counts)\n",
    "plt.xlabel('class')\n",
    "plt.ylabel('# samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now split the data into a 70%-30% training testing split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 800/800 [00:13<00:00, 60.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final loss = 0.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_X,train_y,test_X,test_y = train_test_split(data,0.7)\n",
    "perceptron = Perceptron()\n",
    "perceptron.fit(train_X,train_y,learning_rate=0.00001,iterations=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy = 99.48%\n",
      "Testing accuracy = 98.30%\n"
     ]
    }
   ],
   "source": [
    "evaluate(train_X,train_y,test_X,test_y,perceptron)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limitations of Perceptron algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The algorithm converges only when the data is linearly seperable.\n",
    "- Can take substantial amount of iterations to reach convergence even if data is linearly seperable\n",
    "- No accepted method to find out the learning rate and iteration hyperparameters\n",
    "- It is not a good classifier of datasets which cannot be seperated linearly"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
